{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7125472",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forest\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this chapter we will cover Decision Trees and Random Forest.\n",
    "\n",
    "However, we first need to quickly define entropy of a random variable.\n",
    "\n",
    "## Entropy\n",
    "\n",
    "The **surprisal** of a random event $E$ is defined to be equal to\n",
    "$$\n",
    "-\\log_2(\\mathbb{P}(E)),\n",
    "$$\n",
    "where $\\mathbb{P}(E)$ is the probability that $E$ occurs.\n",
    "\n",
    "So the less likely the event is to occur the bigger its surprisal.\n",
    "\n",
    "## Entropy\n",
    "\n",
    "Suppose $X$ is a finite discrete random variable taking values $x_1, \\dots x_n.$\n",
    "The **entropy** of $X$ is then defined to be the expected value of surprisal, it is denoted $H(X).$ That is\n",
    "$$\n",
    "  H(X) = -\\sum_{i=1}^n p(x_i)\\log_2(p(x_i)),\n",
    "$$\n",
    "where $p$ is the probability mass function of $X.$\n",
    "\n",
    "## Entropy\n",
    "\n",
    "Entropy is used to measure how uncertain the outcome of a random variable is. The higher the entropy the more uncertain.\n",
    "\n",
    "For example, suppose you have a fair coin. Then the outcome of a coin toss is very uncertain, its as likely to go either way.\n",
    "The entropy in this case is\n",
    "$$\n",
    "  -\\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right)-\\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right)= 1.\n",
    "$$\n",
    "This is as large as entropy can be for a Bernoulli random variable.\n",
    "\n",
    "## Entropy\n",
    "\n",
    "Now suppose you have a biased coin that lands on heads 90% of the time. The outcome of the coin toss is then very certain - its going to be heads most of the time. The entropy is also lower\n",
    "$$\n",
    "  -\\frac{9}{10}\\log_2\\left(\\frac{9}{10}\\right)-\\frac{1}{10}\\log_2\\left(\\frac{1}{10}\\right)\\approx 0.47.\n",
    "$$\n",
    "\n",
    "## Entropy\n",
    "\n",
    "Lastly, suppose you have a coin that has heads on both sides. The coin toss has no uncertainty at all with such a coin! Its entropy is $0$, indeed\n",
    "$$\n",
    "  -1\\log_2\\left(1\\right)=0.\n",
    "$$\n",
    "\n",
    "We will use entropy when training decision trees.\n",
    "\n",
    "## Entropy\n",
    "\n",
    "Also last time we used cross-entropy to train logistic regression.\n",
    "\n",
    "Suppose we have two finite discrete random variables $X$ and $Y$ taking the same values $x_1, \\dots, x_n$. Let's say that the pmf of $X$ is $p$ and pmf of $Y$ is $q$. Then cross-entropy is defined to be\n",
    "$$\n",
    "  H(X, Y) = -\\sum_{i=1}^n p(x_i) \\log(q(x_i)).\n",
    "$$\n",
    "\n",
    "When $X$ and $Y$ have the same distribution cross-entropy is equal to regular entropy, if they do not have the same distribution then cross-entropy is strictly larger.\n",
    "\n",
    "## Entropy\n",
    "\n",
    "Cross entropy measures how similar Y is to X. This is not the fully correct interpretation, but it is sufficient. The correct interpretation is a bit more subtle, you can read it [here](https://en.wikipedia.org/wiki/Cross-entropy).\n",
    "\n",
    "Also note that it is not symmetric, that is\n",
    "$$\n",
    "H(X, Y) \\ne H(Y, X)\n",
    "$$\n",
    "in general.\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "I'm sure you've all seen a decision tree before. They look something like this:\n",
    "\n",
    "![](../images/decision-tree.jpg){fig-align=\"center\"}\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "How to train a decision tree?\n",
    "\n",
    "Suppose we are trying to solve a classification problem. That is we have some training data with features and a target variable with $n$ classes.\n",
    "\n",
    "A decision tree is going to sort our training samples into groups, one group for each node. Then we can compute the entropy of each node. When we split a parent node into two nodes we want the split to minimize entropy as much as possible.\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "Define information gain as\n",
    "$$\n",
    "  H(\\text{parent}) - \\left(\\frac{N_{\\text{left}}}{N_{\\text{parent}}}H(\\text{left})+\\frac{N_{\\text{right}}}{N_{\\text{parent}}}H(\\text{right})\\right),\n",
    "$$\n",
    "where $N_\\text{parent}, N_{\\text{left}}, N_{\\text{right}}$ denotes the number of samples in the respective node.\n",
    "\n",
    "For each feature we compute the split that optimizes information gain and then choose the feature with the highest information gain to split on.\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "We then do this procedure iteratively starting from the root node that contains all samples. This algorithm does not produce an optimal tree, but there is no known polynomial time algorithm that does, so it'll have to do.\n",
    "\n",
    "There are other measures you can use to compute information gain instead of entropy, such as [Gini impurity](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity).\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "How to train a decision tree for a regression problem?\n",
    "\n",
    "Suppose the vectors $(y_i, x_i),$ $i=1, \\dots, m$ represent our training data, where $x_i = (x_{i1}, \\dots, x_{in})$ is a vector.\n",
    "So the input to our model is a $n$ dimensional vector $x \\in \\mathbb{R}^n$.\n",
    "We will split the tree on conditions like $x_j \\le s$ or $x_{j} > s,$ where $s$ is some threshold, so the tree will partition the space $\\mathbb{R}^n$ into high dimensional rectangles $R_1, \\dots R_l$.\n",
    "\n",
    "When inferencing, if $x$ lands in $R_k$ we will output the averge value $\\overline{y}_{R_k}$ of all the $y_i,$ such that $x_i$ falls into $R_k,$ from the training data.\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "To fit the tree, we again start from the root node and for the $j$-th feature and threshold $s$ we define\n",
    "$$\n",
    "  R_{l}(j, s) = \\{x_i: x_{ij} \\le s\\} \\text{ and } R_{r}(j, s) = \\{x_i: x_{ij} > s\\}.\n",
    "$$\n",
    "\n",
    "Then we make the split on the feature and threshold that minimises\n",
    "$$\n",
    "\\sum_{x_i \\in R_{l}(j, s)} (y_i - \\overline{y}_{R_{l}(j, s)})^2 + \\sum_{x_i \\in R_{r}(j, s)} (y_i - \\overline{y}_{R_{r}(j, s)})^2\n",
    "$$\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "We then continue this process inductively. This again does not produce an optimal tree but it will be good enough for our purposes.\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "We can train a decision tree using sklearn. We'll use this [dataset](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ad0e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.96      0.94      0.95       111\n",
      "   malignant       0.89      0.93      0.91        60\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.94      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| output-location: slide\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "y = dataset.target_names[dataset.target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=34)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\", random_state=34)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9683ff",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "The main problem with decision trees is that they tend to overfit.\n",
    "\n",
    "**Overfitting** is a phenomenon where a model learns the noise in the training set rather than the signal. It then is not able to generalize to the data outside the training set.\n",
    "\n",
    "![](../images/overfitting.svg){fig-align=\"center\"}\n",
    "\n",
    "## Overfitting\n",
    "\n",
    "Let's illustrate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45de911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Accuracy for different max_depth values'}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGzCAYAAAAMr0ziAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZstJREFUeJzt3Xd4FPXaxvHvpvfQQkhogVBCDR2poiJIU1SqeCgewQIqIiocRRALR49y4AAC+ioqooBSpCiIKCiK9N57T6MkISFtd94/lkRjQglsMpvk/lxXLiazszP3bJbNk5lfsRiGYSAiIiLixFzMDiAiIiJyIypYRERExOmpYBERERGnp4JFREREnJ4KFhEREXF6KlhERETE6algEREREaengkVEREScngoWERERcXoqWEQc7NChQ3To0IHAwEAsFguLFy8u8Axr1qzBYrGwZs2arHUDBw4kLCws23aXL1/m8ccfp1y5clgsFoYPHw5AdHQ0PXr0oHTp0lgsFiZNmlRg2eXmjBs3DovFYtrx27VrR926dU07/t+FhYUxcOBAs2NIPnIzO4A4pw8++IChQ4fSrFkzNmzYYHacQmXAgAEcO3aMt956ixIlStCkSROzI13T22+/zaeffsqYMWMIDw+nVq1aADz//POsXLmSsWPHUq5cOac+hw8++AAfHx/9ssoHZ8+e5cMPP6R79+40aNDA7DhSzKlgkVzNmTOHsLAwNm7cyOHDh6lWrZrZkQqFK1eusH79el555RWGDRtmdpxsPvroI2w2W7Z1P/30E3fccQdjx47Nsf6BBx5g5MiRBRnxlnzwwQeUKVNGBUs+OHv2LK+//jphYWEqWMR0uiUkORw7dozff/+diRMnEhQUxJw5c8yOdE1JSUlmR8gmNjYWgBIlSjhsn446R3d3dzw9PbOti4mJyTXrtdbfqoyMDNLS0hy2PxEpflSwSA5z5syhZMmSdOnShR49elyzYLl06RLPP/88YWFheHp6UqFCBfr3709cXFzWNikpKYwbN44aNWrg5eVFSEgIDz30EEeOHAFyb2sBcPz4cSwWC59++mnWuoEDB+Ln58eRI0fo3Lkz/v7+9OvXD4Bff/2Vnj17UqlSJTw9PalYsSLPP/88V65cyZF7//799OrVi6CgILy9valZsyavvPIKAD///DMWi4VFixbleN6XX36JxWJh/fr1ub4e48aNo3LlygC8+OKLWCyWbG1Gtm3bRqdOnQgICMDPz4977rmHP/74I9s+Pv30UywWC2vXruXpp5+mbNmyVKhQIdfjZTp9+jTdu3fH19eXsmXL8vzzz5Oamppju7+2Ycl83Y8dO8by5cuxWCxZr7fFYsEwDKZNm5a1PtOlS5cYPnw4FStWxNPTk2rVqvHOO+9ku3KT+bN77733mDRpEuHh4Xh6erJ3796s179Hjx6UKlUKLy8vmjRpwpIlS3J9HX777TdGjBhBUFAQvr6+PPjgg1lFIdjbLezZs4e1a9dmZW3Xrt01X6u/Zps2bRpVq1bFx8eHDh06cOrUKQzD4I033qBChQp4e3vzwAMPcOHChWz7+Pbbb+nSpQuhoaF4enoSHh7OG2+8gdVqzdpm3759eHt7079//2zPXbduHa6urrz88svXzJibdevW0bRpU7y8vAgPD2fmzJnX3PaLL76gcePGeHt7U6pUKfr06cOpU6eybZPZ/mTLli20bNkSb29vqlSpwowZM7K2WbNmDU2bNgVg0KBB2d4jf7V3717uuusufHx8KF++PO++++4Nz6du3brcddddOdbbbDbKly9Pjx49sta99957tGzZktKlS+Pt7U3jxo355ptvbniMa7XxyXxvHT9+PNv677//njZt2uDr64u/vz9dunRhz5492baJiopi0KBBVKhQAU9PT0JCQnjggQdy7Evyh24JSQ5z5szhoYcewsPDg759+zJ9+nQ2bdqU9eEF9saabdq0Yd++fTz22GM0atSIuLg4lixZwunTpylTpgxWq5WuXbuyevVq+vTpw3PPPUdiYiKrVq1i9+7dhIeH5zlbRkYGHTt2pHXr1rz33nv4+PgA8PXXX5OcnMxTTz1F6dKl2bhxI1OmTOH06dN8/fXXWc/fuXMnbdq0wd3dnSFDhhAWFsaRI0dYunQpb731Fu3ataNixYrMmTOHBx98MMfrEh4eTosWLXLN9tBDD1GiRAmef/55+vbtS+fOnfHz8wNgz549tGnThoCAAF566SXc3d2ZOXMm7dq1Y+3atTRv3jzbvp5++mmCgoJ47bXXrnuF5cqVK9xzzz2cPHmSZ599ltDQUGbPns1PP/103dexVq1azJ49m+eff54KFSrwwgsvANCwYUNmz57NP/7xD+69995sv3CTk5O58847OXPmDE888QSVKlXi999/Z/To0Zw7dy5Hw9xZs2aRkpLCkCFD8PT0pFSpUuzZs4dWrVpRvnx5Ro0aha+vL/Pnz6d79+4sWLAgx2v+zDPPULJkScaOHcvx48eZNGkSw4YNY968eQBMmjSJZ555Bj8/v6yiMzg4+LrnDvafZVpaGs888wwXLlzg3XffpVevXtx9992sWbOGl19+mcOHDzNlyhRGjhzJJ598kvXcTz/9FD8/P0aMGIGfnx8//fQTr732GgkJCfznP//Jen3feOMNXnzxRXr06MH9999PUlISAwcOJCIigvHjx98wY6Zdu3bRoUMHgoKCGDduHBkZGYwdOzbX83zrrbcYM2YMvXr14vHHHyc2NpYpU6bQtm1btm3blu2q2cWLF+ncuTO9evWib9++zJ8/n6eeegoPDw8ee+wxatWqxfjx43nttdcYMmQIbdq0AaBly5bZ9nHffffx0EMP0atXL7755htefvll6tWrR6dOna55Tr1792bcuHFERUVRrly5rPXr1q3j7Nmz9OnTJ2vd5MmTuf/+++nXrx9paWnMnTuXnj17smzZMrp06XLTr+P1zJ49mwEDBtCxY0feeecdkpOTmT59Oq1bt2bbtm1Zhf7DDz/Mnj17eOaZZwgLCyMmJoZVq1Zx8uTJHA3aJR8YIn+xefNmAzBWrVplGIZh2Gw2o0KFCsZzzz2XbbvXXnvNAIyFCxfm2IfNZjMMwzA++eQTAzAmTpx4zW1+/vlnAzB+/vnnbI8fO3bMAIxZs2ZlrRswYIABGKNGjcqxv+Tk5BzrJkyYYFgsFuPEiRNZ69q2bWv4+/tnW/fXPIZhGKNHjzY8PT2NS5cuZa2LiYkx3NzcjLFjx+Y4Tm65//Of/2Rb3717d8PDw8M4cuRI1rqzZ88a/v7+Rtu2bbPWzZo1ywCM1q1bGxkZGdc9lmEYxqRJkwzAmD9/fta6pKQko1q1ajle1wEDBhiVK1fO9vzKlSsbXbp0ybFfwBg6dGi2dW+88Ybh6+trHDx4MNv6UaNGGa6ursbJkyezvQYBAQFGTExMtm3vueceo169ekZKSkrWOpvNZrRs2dKoXr16jtehffv22X42zz//vOHq6prtZ1OnTh3jzjvvvMYrlF1mtqCgoGz7GD16tAEYkZGRRnp6etb6vn37Gh4eHtny5vZee+KJJwwfH59s21mtVqN169ZGcHCwERcXZwwdOtRwc3MzNm3adFNZM3Xv3t3w8vLK9p7du3ev4erqavz1I/z48eOGq6ur8dZbb2V7/q5duww3N7ds6++8804DMN5///2sdampqUaDBg2MsmXLGmlpaYZhGMamTZty/D/8+z4+//zzbPsoV66c8fDDD1/3nA4cOGAAxpQpU7Ktf/rppw0/P79sr/HfX++0tDSjbt26xt13351tfeXKlY0BAwZkfT927Fgjt19xme+tY8eOGYZhGImJiUaJEiWMwYMHZ9suKirKCAwMzFp/8eLFXP9vS8HRLSHJZs6cOQQHB2ddrrVYLPTu3Zu5c+dmu+S9YMECIiMjc/xFnPmczG3KlCnDM888c81tbsVTTz2VY523t3fWclJSEnFxcbRs2RLDMNi2bRtgb1/yyy+/8Nhjj1GpUqVr5unfvz+pqanZLjvPmzePjIwMHn300TzntVqt/PDDD3Tv3p2qVatmrQ8JCeGRRx5h3bp1JCQkZHvO4MGDcXV1veG+v/vuO0JCQrJdQvfx8WHIkCF5znkjX3/9NW3atKFkyZLExcVlfbVv3x6r1covv/ySbfuHH36YoKCgrO8vXLjATz/9RK9evUhMTMx6/vnz5+nYsSOHDh3izJkz2fYxZMiQbD+bNm3aYLVaOXHixG2dS8+ePQkMDMz6PvMK16OPPoqbm1u29Wlpadly/fW9lnkebdq0ITk5mf3792c95uLiwqeffsrly5fp1KkTH3zwAaNHj85Tjyur1crKlSvp3r17tvdsrVq16NixY7ZtFy5ciM1mo1evXtl+PuXKlaN69er8/PPP2bZ3c3PjiSeeyPrew8ODJ554gpiYGLZs2XJT+fz8/LL9n/Dw8KBZs2YcPXr0us+rUaMGDRo0yLpSlnmu33zzDd26dcv2Gv91+eLFi8THx9OmTRu2bt16UxlvZNWqVVy6dIm+fftme91cXV1p3rx51uvm7e2Nh4cHa9as4eLFiw45tuSNChbJYrVamTt3LnfddRfHjh3j8OHDHD58mObNmxMdHc3q1auztj1y5MgNx2A4cuQINWvWzPYL4Ha5ubnl2qbj5MmTDBw4kFKlSuHn50dQUBB33nknAPHx8QBZH6I3yh0REUHTpk2ztd2ZM2cOd9xxxy31loqNjSU5OZmaNWvmeKxWrVrYbLYcbQyqVKlyU/s+ceIE1apVy1EA5nas23Xo0CFWrFhBUFBQtq/27dsD9oa6f/X3czh8+DCGYTBmzJgc+8jspfT3ffy9sCxZsiTAbf/C+Pt+M4uXihUr5rr+r8fbs2cPDz74IIGBgQQEBBAUFJT1SzvzvZYpPDyccePGsWnTJurUqcOYMWPylDM2NpYrV65QvXr1HI/9/Wd86NAhDMOgevXqOV7fffv25XhtQ0ND8fX1zbauRo0aADfdJqNChQo53nslS5a8qZ9P7969+e2337KKwTVr1hATE0Pv3r2zbbds2TLuuOMOvLy8KFWqFEFBQUyfPj3Ha32rDh06BMDdd9+d43X74Ycfsl43T09P3nnnHb7//nuCg4Np27Yt7777LlFRUQ7JITemNiyS5aeffuLcuXPMnTuXuXPn5nh8zpw5dOjQwaHHvNaVlr9ezfkrT09PXFxccmx77733cuHCBV5++WUiIiLw9fXlzJkzDBw4MEdX3pvRv39/nnvuOU6fPk1qaip//PEHU6dOzfN+btVf/6p0FjabjXvvvZeXXnop18czf9ll+vs5ZP4cRo4cmePqQKa/F4TXuspkGMZNZb6Wa+33Rse7dOkSd955JwEBAYwfP57w8HC8vLzYunUrL7/8cq7vtR9++AGwdxE+f/58tjYbjmSz2bBYLHz//fe5nkdmeypHup2fT+/evRk9ejRff/01w4cPZ/78+QQGBnLfffdlbfPrr79y//3307ZtWz744ANCQkJwd3dn1qxZfPnll9fd/81+tmT+zGbPnp3rz+avf3ANHz6cbt26sXjxYlauXMmYMWOYMGECP/30Ew0bNrzhOcvtUcEiWebMmUPZsmWZNm1ajscWLlzIokWLmDFjBt7e3oSHh7N79+7r7i88PJwNGzaQnp6Ou7t7rttk/sV86dKlbOvzcsl/165dHDx4kM8++yxbI9FVq1Zl2y7zdsyNcgP06dOHESNG8NVXX3HlyhXc3d1z/OV3s4KCgvDx8eHAgQM5Htu/fz8uLi45/rK/WZUrV2b37t0YhpHtAzq3Y92u8PBwLl++nHVFJa8yX393d/db3kduCnK01zVr1nD+/HkWLlxI27Zts9YfO3Ys1+1nzJjBqlWreOutt5gwYQJPPPEE33777U0fL7MnW+ZVgL/6+884PDwcwzCoUqVKjuIxN2fPniUpKSnbVZaDBw8CZDUgzc/XtkqVKjRr1ox58+YxbNgwFi5cSPfu3bN1vV+wYAFeXl6sXLky2/pZs2bdcP9//Wz5a2Pjv3+2ZDb+L1u27E29L8PDw3nhhRd44YUXOHToEA0aNOD999/niy++uOFz5fbolpAA9t4mCxcupGvXrvTo0SPH17Bhw0hMTMzqfvrwww+zY8eOXLv/Zv519fDDDxMXF5frlYnMbSpXroyrq2uO9g8ffPDBTWfP/Cvvr3/VGYbB5MmTs20XFBRE27Zt+eSTTzh58mSueTKVKVOGTp068cUXXzBnzhzuu+8+ypQpc9OZ/p6vQ4cOfPvtt9kutUdHR/Pll1/SunVrAgICbmnfnTt35uzZs9na2yQnJ/Phhx/e0v6up1evXqxfv56VK1fmeOzSpUtkZGRc9/lly5alXbt2zJw5k3PnzuV4/K/dlfPC19c3R8GbX3J7r6WlpeX6fj127BgvvvgiDz/8MP/617947733WLJkCZ9//nmejtexY0cWL16c7T27b9++HD+Hhx56CFdXV15//fUc72fDMDh//ny2dRkZGdm6R6elpTFz5kyCgoJo3LgxQFYxk1+vb+/evfnjjz/45JNPiIuLy/FHgaurKxaLJdtVkePHj9/UdBeZhchfP1uSkpL47LPPsm3XsWNHAgICePvtt0lPT8+xn8z3ZXJyMikpKTmO4e/vn+swAuJ4usIiACxZsoTExETuv//+XB+/4447sgaR6927Ny+++CLffPMNPXv25LHHHqNx48ZcuHCBJUuWMGPGDCIjI+nfvz+ff/45I0aMYOPGjbRp04akpCR+/PFHnn76aR544AECAwPp2bMnU6ZMwWKxEB4ezrJly3Lcb7+eiIgIwsPDGTlyJGfOnCEgIIAFCxbkeh/9f//7H61bt6ZRo0YMGTKEKlWqcPz4cZYvX8727duzbdu/f/+sxqxvvPHGzb+YuXjzzTdZtWoVrVu35umnn8bNzY2ZM2eSmpp6U+NWXMvgwYOZOnUq/fv3Z8uWLYSEhDB79uys7t6O9OKLL7JkyRK6du3KwIEDady4MUlJSezatYtvvvmG48eP37ComzZtGq1bt6ZevXoMHjyYqlWrEh0dzfr16zl9+jQ7duzIc67GjRszffp03nzzTapVq0bZsmW5++67b/U0r6tly5aULFmSAQMG8Oyzz2KxWJg9e3auBcJjjz2Gt7c306dPB+CJJ55gwYIFPPfcc7Rv357Q0NCbOubrr7/OihUraNOmDU8//TQZGRlMmTKFOnXqsHPnzqztwsPDefPNNxk9ejTHjx+ne/fu+Pv7c+zYMRYtWsSQIUOyjVwcGhrKO++8w/Hjx6lRowbz5s1j+/btfPjhh1lXRMPDwylRogQzZszA398fX19fmjdvftNtrG6kV69ejBw5kpEjR1KqVKkcVzi6dOnCxIkTue+++3jkkUeIiYlh2rRpVKtWLdu556ZDhw5UqlSJf/7zn7z44ou4urryySefEBQUlK34CwgIYPr06fzjH/+gUaNG9OnTJ2ub5cuX06pVK6ZOncrBgwe555576NWrF7Vr18bNzY1FixYRHR2drRu25KOC7pYkzqlbt26Gl5eXkZSUdM1tBg4caLi7uxtxcXGGYRjG+fPnjWHDhhnly5c3PDw8jAoVKhgDBgzIetww7F0SX3nlFaNKlSqGu7u7Ua5cOaNHjx7ZuvfGxsYaDz/8sOHj42OULFnSeOKJJ4zdu3fn2q3Z19c312x79+412rdvb/j5+RllypQxBg8ebOzYsSPXLpm7d+82HnzwQaNEiRKGl5eXUbNmTWPMmDE59pmammqULFnSCAwMNK5cuXIzL+M1uzUbhmFs3brV6Nixo+Hn52f4+PgYd911l/H7779n2yazy2Veur6eOHHCuP/++w0fHx+jTJkyxnPPPWesWLHC4d2aDcPeBXT06NFGtWrVDA8PD6NMmTJGy5Ytjffeey+rK+z1XgPDMIwjR44Y/fv3N8qVK2e4u7sb5cuXN7p27Wp88803N3wdcusGHxUVZXTp0sXw9/c3gOt2cb5Wtsz9fv3119nW55bjt99+M+644w7D29vbCA0NNV566SVj5cqV2XJNnjzZAIwFCxZk29/JkyeNgIAAo3PnztfMmJu1a9cajRs3Njw8PIyqVasaM2bMuGa33QULFhitW7c2fH19DV9fXyMiIsIYOnSoceDAgaxt7rzzTqNOnTrG5s2bjRYtWhheXl5G5cqVjalTp+bY37fffmvUrl3bcHNzy/b/KXMff5fb++x6WrVqZQDG448/nuvjH3/8sVG9enXD09PTiIiIMGbNmpXruf+9W7NhGMaWLVuM5s2bGx4eHkalSpWMiRMn5ujWnOnnn382OnbsaAQGBhpeXl5GeHi4MXDgQGPz5s2GYRhZXdMjIiIMX19fIzAw0GjevHm2IQUkf1kM4zZbr4kUURkZGYSGhtKtWzc+/vhjs+OIOEy7du2Ii4u7qfZcIs5CbVhErmHx4sXExsbmGF5dREQKntqwiPzNhg0b2LlzJ2+88QYNGzbMGs9FxJEuX77M5cuXr7tNUFDQTQ0gKFIcqGAR+Zvp06fzxRdf0KBBgxwTvYk4ynvvvcfrr79+3W2OHTumOWpErlIbFhERExw9evSGQ9i3bt0aLy+vAkok4txUsIiIiIjTU6NbERERcXpFpg2LzWbj7Nmz+Pv7F+hQ3SIiInLrDMMgMTGR0NDQHHPF/VWRKVjOnj17y/OxiIiIiLlOnTpFhQoVrvl4kSlY/P39AfsJ3+q8LCIiIlKwEhISqFixYtbv8WspMgVL5m2ggIAAFSwiIiKFzI2ac6jRrYiIiDg9FSwiIiLi9FSwiIiIiNMrMm1YbobVaiU9Pd3sGIWSq6srbm5u6jIuIiKmKDYFy+XLlzl9+jQa2PfW+fj4EBISgoeHh9lRRESkmCkWBYvVauX06dP4+PgQFBSkqwR5ZBgGaWlpxMbGcuzYMapXr37dwX1EREQcrVgULOnp6RiGQVBQEN7e3mbHKZS8vb1xd3fnxIkTpKWlaUI2EREpUMXqz2RdWbk9uqoiIiJm0W8gERERcXoqWERERMTp5blg+eWXX+jWrRuhoaFYLBYWL158w+esWbOGRo0a4enpSbVq1fj0009zbDNt2jTCwsLw8vKiefPmbNy4Ma/R5DrCwsKYNGmS2TFERERuSZ4LlqSkJCIjI5k2bdpNbX/s2DG6dOnCXXfdxfbt2xk+fDiPP/44K1euzNpm3rx5jBgxgrFjx7J161YiIyPp2LEjMTExeY1XpLRr147hw4c7ZF+bNm1iyJAhDtmXiIhIQctzL6FOnTrRqVOnm95+xowZVKlShffffx+AWrVqsW7dOv773//SsWNHACZOnMjgwYMZNGhQ1nOWL1/OJ598wqhRo3Ldb2pqKqmpqVnfJyQk5PVUCj3DMLBarbi53fjHGBQUVACJRCSvTl1I5rtd54hKSDE7isgNjbi3Bv5e7qYcO9+7Na9fv5727dtnW9exY8esKwdpaWls2bKF0aNHZz3u4uJC+/btWb9+/TX3O2HCBF5//fVbymQYBlfSrbf03Nvl7e56U72VBg4cyNq1a1m7di2TJ08GYNasWQwaNIjvvvuOV199lV27dvHDDz9QsWJFRowYwR9//EFSUhK1atViwoQJ2V73sLAwhg8fnvW6WywWPvroI5YvX87KlSspX74877//Pvfff3++nLeI/Olc/BWW7zzH0p3n2HHqktlxRG7aU+3Ci27BEhUVRXBwcLZ1wcHBJCQkcOXKFS5evIjVas11m/37919zv6NHj2bEiBFZ3yckJFCxYsWbynQl3Urt11beeMN8sHd8R3w8bvyyT548mYMHD1K3bl3Gjx8PwJ49ewAYNWoU7733HlWrVqVkyZKcOnWKzp0789Zbb+Hp6cnnn39Ot27dOHDgAJUqVbrmMV5//XXeffdd/vOf/zBlyhT69evHiRMnKFWqlGNOVkSyxCam8v3ucyzdcZZNxy9mrXexQIvw0kRWKIFGXhBndzO/v/JLoR04ztPTE09PT7Nj5JvAwEA8PDzw8fGhXLlyAFkF3Pjx47n33nuzti1VqhSRkZFZ37/xxhssWrSIJUuWMGzYsGseY+DAgfTt2xeAt99+m//9739s3LiR++67Lz9OSaTYuZiUxoo9USzdcZY/jp7H9peZQZqFlaJrZAid6oYQ5F90P8tEHCXfC5Zy5coRHR2dbV10dDQBAQF4e3vj6uqKq6trrttk/qJ2NG93V/aO75gv+76ZY9+uJk2aZPv+8uXLjBs3juXLl3Pu3DkyMjK4cuUKJ0+evO5+6tevn7Xs6+tLQEBAsW/oLHK7ElLS+WFPNMt2nmXdoTgy/lKlRFYsQbf6IXSpH0JIoEbdFsmLfC9YWrRowXfffZdt3apVq2jRogUAHh4eNG7cmNWrV9O9e3cAbDYbq1evvu7VgdthsVhMvax1u3x9fbN9P3LkSFatWsV7771HtWrV8Pb2pkePHqSlpV13P+7u2e9DWiwWbDabw/OKFHVJqRn8uC+aZTvPsfZALGnWP/8f1Q4JoFtkKF3rh1CxlI+JKUUKtzz/1r58+TKHDx/O+v7YsWNs376dUqVKUalSJUaPHs2ZM2f4/PPPAXjyySeZOnUqL730Eo899hg//fQT8+fPZ/ny5Vn7GDFiBAMGDKBJkyY0a9aMSZMmkZSUlNVrqLjy8PDAar1x4+DffvuNgQMH8uCDDwL2n9Hx48fzOZ1I8ZaSbmXNgRiW7jjH6v3RpKT/WaRUK+tHt/qhdI0MITzIz8SUIkVHnguWzZs3c9ddd2V9n9nwdcCAAXz66aecO3cu262IKlWqsHz5cp5//nkmT55MhQoV+L//+7+sLs0AvXv3JjY2ltdee42oqCgaNGjAihUrcjTELW7CwsLYsGEDx48fx8/P75pXP6pXr87ChQvp1q0bFouFMWPG6EqJSD5Iy7Dx66FYlu08xw97okhK+/MPirDSPnS9WqTUDPbX3GUiDpbngqVdu3YYhnHNx3MbxbZdu3Zs27btuvsdNmxYvt0CKqxGjhzJgAEDqF27NleuXGHWrFm5bjdx4kQee+wxWrZsSZkyZXj55ZeL5bg0Ivkhw2rj9yPnWbbzLCt2R5GQkpH1WPkS3nStH0LX+qHULR+gIkUkH1mM61UfhUhCQgKBgYHEx8cTEBCQ7bGUlBSOHTtGlSpV8PLyMilh4afXUYoLq81g0/ELLN1hL1LOJ/3ZHqysvyddrhYpjSqVUJEicpuu9/v7rwpvy1MREQcyDIOtJy+xdMdZvtt1jpjEP0fSLuXrQae65egWGUrTsFK4uqhIESloKlhEpNgyDIPdZxJYtvMsy3ae48ylK1mPBXi5cd/VIqVF1dK4uWpyexEzqWARkWLnQFQiS3ecZdnOsxw/n5y13tfDlQ51ytG1fghtqgfh4aYiRcRZqGARkWLhaOxllu44x7KdZzkUczlrvZe7C/fUCqZb/RDa1SyLlwMGdxQRx1PBIiJF1qkLySzbaZ+/Z++5P3vOebi6cGfNILpFhnJPRFl8PfVRKOLs9L9URIqUzJmQl+08x/a/zITs5mKhdfUydKsfyr11ggkwacZZEbk1KlhEpNDLnAl52Y5zbDx+IWt95kzIXeuHcl+dcpT09TAxpYjcDhUsIlIoXUpOY8XuKJbuPMv6I5oJWaSoU8EiIoVGQko6q/ZEs1QzIYsUOypYRMSpGYbB97ujWLztDGsOxpKWkX0m5K6RIXStF0ql0poJWaQoU8HixNq1a0eDBg2YNGmSQ/Y3cOBALl26xOLFix2yP5GC8O7KA0xfcyTre82ELFI8qWAREaf1y8HYrGJlcJsqPNy4gmZCFimmiucwjoYBaUnmfN3kXJMDBw5k7dq1TJ48GYvFgsVi4fjx4+zevZtOnTrh5+dHcHAw//jHP4iLi8t63jfffEO9evXw9vamdOnStG/fnqSkJMaNG8dnn33Gt99+m7W/NWvW5NMLLHL7YhNTGTF/BwCP3lGJV7rUJqKcZkQWKa6K5xWW9GR4O9ScY//rLHj43nCzyZMnc/DgQerWrcv48eMBcHd3p1mzZjz++OP897//5cqVK7z88sv06tWLn376iXPnztG3b1/effddHnzwQRITE/n1118xDIORI0eyb98+EhISmDVrFgClSpXK11MVuVU2m8GI+duJu5xKRDl/Xu1S2+xIImKy4lmwFAKBgYF4eHjg4+NDuXLlAHjzzTdp2LAhb7/9dtZ2n3zyCRUrVuTgwYNcvnyZjIwMHnroISpXrgxAvXr1srb19vYmNTU1a38izurDX4/y66E4vNxdmNK3oYbLF5FiWrC4+9ivdJh17Fu0Y8cOfv75Z/z8cjY0PHLkCB06dOCee+6hXr16dOzYkQ4dOtCjRw9Klix5O4lFCtS2kxd5b+UBAMZ1q0P1YH+TE4mIMyieBYvFclO3ZZzN5cuX6datG++8806Ox0JCQnB1dWXVqlX8/vvv/PDDD0yZMoVXXnmFDRs2UKVKFRMSi+RNQko6z87dRobNoEv9EHo3rWh2JBFxEsWz0W0h4eHhgdVqzfq+UaNG7Nmzh7CwMKpVq5bty9fXXoBZLBZatWrF66+/zrZt2/Dw8GDRokW57k/EmRiGwb8W7uLUhStUKOnNhIfqqYGtiGRRweLEwsLC2LBhA8ePHycuLo6hQ4dy4cIF+vbty6ZNmzhy5AgrV65k0KBBWK1WNmzYwNtvv83mzZs5efIkCxcuJDY2llq1amXtb+fOnRw4cIC4uDjS09NNPkORP83ffIplO8/h5mJhSt+GmpxQRLJRweLERo4ciaurK7Vr1yYoKIi0tDR+++03rFYrHTp0oF69egwfPpwSJUrg4uJCQEAAv/zyC507d6ZGjRq8+uqrvP/++3Tq1AmAwYMHU7NmTZo0aUJQUBC//fabyWcoYncoOpGxS/YAMLJjTRpWUrsrEcnOYhg3OTCIk0tISCAwMJD4+HgCAgKyPZaSksKxY8eoUqUKXl5eJiUs/PQ6Sn5ISbfSfdpv7I9KpE31Mnw2qBkuLroVJFJcXO/391/pCouImOrN5XvZH5VIGT8P3u8VqWJFRHKlgkVETLNi9zm++OMkABN7NaCsv67ciUjuVLCIiClOX0zmpW92AvDEnVVpWyPI5EQi4sxUsIhIgcuw2hg+dzsJKRk0qFiCkR1qmh1JRJxcsSpYikj7YtPo9RNHmbz6EJtPXMTf040pfRvi7lqsPopE5BYUi08JV1f7PCRpaWkmJynckpOTAfskjCK36vfDcUz9+TAAbz9Uj4qlbn26ChEpPorF0Pxubm74+PgQGxuLu7s7Li7Fok5zGMMwSE5OJiYmhhIlSmQVgCJ5df5yKsPnbccwoE/TinSLNGnWdBEpdIpFwWKxWAgJCeHYsWOcOHHC7DiFVokSJTTTs9wywzAY+fUOYhJTqVbWj7Hd6pgdSUQKkWJRsIB9Hp3q1avrttAtcnd315UVuS0frzvGzwdi8XBzYeojDfH20PtJRG5esSlYAFxcXDRCq4gJdp2O550V+wEY07U2EeWuPZqliEhu1JhDRPLV5dQMnvlqK+lWg451gnm0eSWzI4lIIaSCRUTy1ZjFuzl+PpnyJbx59+FILBYNvS8ieaeCRUTyzYItp1m07QyuLhYm92lAoI+6xIvIrVHBIiL54mjsZcZ8uxuA59tXp0lYKZMTiUhhpoJFRBwuNcPKsC+3kZxmpUXV0jzVrprZkUSkkFPBIiION+G7/ew9l0ApXw8m9WmAq4varYjI7VHBIiIOtWpvNJ/+fhyA93rWJzhAQwmIyO1TwSIiDnMu/govfrMDgH+2rsLdEcEmJxKRokIFi4g4hNVmMHzudi4lp1OvfCAv3VfT7EgiUoSoYBERh5j602E2HLuAr4crU/o2xNNNQ++LiOOoYBGR27bh6Hkmrz4IwJsP1iWsjK/JiUSkqFHBIiK35WJSGsPnbcdmwMONKvBgwwpmRxKRIkgFi4jcMsMwePGbnZyLT6FqGV/GP1DH7EgiUkSpYBGRW/b5+hP8uC8aD1cX/te3Ib6exWoCeBEpQCpYROSW7Dkbz1vL9wEwunMEdcsHmpxIRIoyFSwikmfJaRk889U20qw22tcqy8CWYWZHEpEiTgWLiOTZ2G/3cDQ2iXIBXrzbIxKLRUPvi0j+UsEiInny7fYzfL3lNC4WmNSnAaV8PcyOJCLFgAoWEblpx+OSeGXRbgCG3V2dO6qWNjmRiBQXKlhE5KakZdh4du42Lqdm0CysFM/eXc3sSCJSjKhgEZGb8p+V+9l5Op5Ab3cm9WmAm6s+PkSk4OgTR0Ru6OcDMXz06zEA/tOjPqElvE1OJCLFjQoWEbmumIQURs7fAcCAFpXpUKecyYlEpDhSwSIi12S1GQyft53zSWnUCglgdOdaZkcSkWJKBYuIXNOMtUf4/ch5vN1dmdK3IV7urmZHEpFiSgWLiORqy4kLTFx1EIDXH6hDtbJ+JicSkeJMBYuI5BCfnM6zX23HajN4oEEoPRtXMDuSiBRzKlhEJBvDMBi1cCdnLl2hcmkf3uxeV0Pvi4jpVLCISDZfbjzJ97ujcHOx8L8+DfH3cjc7koiIChYR+dOBqETGL90LwMv3RRBZsYS5gURErlLBIiIAXEmzMuzLraRm2LizRhD/bF3F7EgiIllUsIgIAOOX7eVQzGWC/D15v1ckLi5qtyIizkMFi4iwfOc5vtp4EosFJvVuQBk/T7MjiYhkc0sFy7Rp0wgLC8PLy4vmzZuzcePGa26bnp7O+PHjCQ8Px8vLi8jISFasWJFtG6vVypgxY6hSpQre3t6Eh4fzxhtvYBjGrcQTkTw4dSGZUQt3AvDUneG0qlbG5EQiIjnluWCZN28eI0aMYOzYsWzdupXIyEg6duxITExMrtu/+uqrzJw5kylTprB3716efPJJHnzwQbZt25a1zTvvvMP06dOZOnUq+/bt45133uHdd99lypQpt35mInJD6VYbz3y1jcSUDBpVKsHz99YwO5KISK4sRh4vYzRv3pymTZsydepUAGw2GxUrVuSZZ55h1KhRObYPDQ3llVdeYejQoVnrHn74Yby9vfniiy8A6Nq1K8HBwXz88cfX3OZGEhISCAwMJD4+noCAgLyckkix9c6K/UxfcwR/Lze+e7YNFUv5mB1JRIqZm/39nacrLGlpaWzZsoX27dv/uQMXF9q3b8/69etzfU5qaipeXl7Z1nl7e7Nu3bqs71u2bMnq1as5eNA+DPiOHTtYt24dnTp1umaW1NRUEhISsn2JyM379VAs09ccAeCdh+urWBERp+aWl43j4uKwWq0EBwdnWx8cHMz+/ftzfU7Hjh2ZOHEibdu2JTw8nNWrV7Nw4UKsVmvWNqNGjSIhIYGIiAhcXV2xWq289dZb9OvX75pZJkyYwOuvv56X+CJyVWxiKs/P2wHAI80r0bleiMmJRESuL997CU2ePJnq1asTERGBh4cHw4YNY9CgQbi4/Hno+fPnM2fOHL788ku2bt3KZ599xnvvvcdnn312zf2OHj2a+Pj4rK9Tp07l96mIFAk2m8ELX+8g7nIqNYL9eK1rbbMjiYjcUJ6usJQpUwZXV1eio6OzrY+OjqZcuXK5PicoKIjFixeTkpLC+fPnCQ0NZdSoUVStWjVrmxdffJFRo0bRp08fAOrVq8eJEyeYMGECAwYMyHW/np6eeHqq66VIXn3061F+ORiLl7sLUx9phJe7q9mRRERuKE9XWDw8PGjcuDGrV6/OWmez2Vi9ejUtWrS47nO9vLwoX748GRkZLFiwgAceeCDrseTk5GxXXABcXV2x2Wx5iSciN7D91CX+s/IAAK91rUONYH+TE4mI3Jw8XWEBGDFiBAMGDKBJkyY0a9aMSZMmkZSUxKBBgwDo378/5cuXZ8KECQBs2LCBM2fO0KBBA86cOcO4ceOw2Wy89NJLWfvs1q0bb731FpUqVaJOnTps27aNiRMn8thjjznoNEUkISWdZ77aSobNoEu9EPo2q2h2JBGRm5bngqV3797Exsby2muvERUVRYMGDVixYkVWQ9yTJ09mu1qSkpLCq6++ytGjR/Hz86Nz587Mnj2bEiVKZG0zZcoUxowZw9NPP01MTAyhoaE88cQTvPbaa7d/hiKCYRi8smg3py5coXwJb95+qB4Wi4beF5HCI8/jsDgrjcMicm3zN53ipQU7cXWxMP+JFjSuXNLsSCIiQD6NwyIihc/hmEReW7IbgBc61FCxIiKFkgoWkSIsJd3KsC+3kZJuo3W1MjzZNtzsSCIit0QFi0gR9tbyfeyPSqSMnwcTe0fi4qJ2KyJSOKlgESmiVuyOYvYfJwB4v1cDyvp73eAZIiLOSwWLSBF05tIVXl6wE4AhbatyZ40gkxOJiNweFSwiRUyG1cZzX20j/ko6kRUCGdmhptmRRERumwoWkSLmf6sPsfnERfw83ZjStxEebvpvLiKFnz7JRIqQ34/EMeXnwwC8/VA9KpX2MTmRiIhjqGARKSLOX07l+XnbMQzo1aQC90eGmh1JRMRhVLCIFAGGYfDiNzuJTkglPMiXcffXMTuSiIhDqWARKQI++e04P+2PwcPNhSl9G+HjkedpwkREnJoKFpFCbtfpeP79/T4AXu1Si9qhmktLRIoeFSwihdi2kxcZ9OlG0q0GHWoH8487KpsdSUQkX+i6sUgh9d2uczw/bzupGTZqhQTwbo/6WCwael9EiiYVLCKFjGEYTF97hHdXHADg7oiy/K9vQ/w89d9ZRIoufcKJFCJpGTZeXbyL+ZtPAzCwZRhjutbGVZMaikgRp4JFpJCIT07nyS+2sP7oeVwsMLZbHQa0DDM7lohIgVDBIlIInDifxKBPN3E0NglfD1emPNKQuyOCzY4lIlJgVLCIOLnNxy8wZPYWLiSlERLoxccDmqrrsogUOypYRJzYt9vP8OLXO0mz2qhXPpCPBzShbICX2bFERAqcChYRJ2QYBv9bfZj//ngQgA61g5nUp4FGsBWRYkuffiJOJjXDyqgFu1i07QwAQ9pWZdR9EbioJ5CIFGMqWEScyIWkNJ6YvZlNxy/i6mLhjQfq8kjzSmbHEhExnQoWESdxNPYygz7dxInzyfh7uvHBo41oUz3I7FgiIk5BBYuIE/jj6HmemL2F+CvplC/hzaxBTakR7G92LBERp6GCRcRk32w5zeiFO0m3GjSoWIKP+jchyN/T7FgiIk5FBYuISWw2g4mrDjL158MAdKkXwvu9IvFydzU5mYiI81HBImKClHQrI7/ewbKd5wAYelc4L9xb89Z6Ap3aBHsWgmE4OKUTcfeCxgOhZJjZSUTEJCpYRApY3OVUBn++mW0nL+HuauHtB+vRs0nFW9uZNR3m94fEs44N6Yx2fg2DfwJ/TUkgUhypYBEpQIeiExn06SZOX7xCgJcbM//RhBbhpW99h/uX24sVn9L2KxBF1Z7FcOEIzH0EBi4Dd2+zE4lIAVPBIlJA1h2K46k5W0hMyaByaR8+GdiU8CC/29vppv+z/9t4ENwz5vZDOqsG/eCju+HMZvh2GDz8f2DRQHoixYmL2QFEioOvNp5kwKyNJKZk0KRySRY93er2i5XovXD8V7C4QpNBjgnqrEqHQ+8vwMUNdn8Dv/zH7EQiUsBUsIjkI5vNYMJ3+xi9cBdWm0H3BqHMGdycUr4et7/zzKsrEZ0hsMLt78/ZVWkDXSbal39+C3YvNDePiBQoFSwi+eRKmpWn5mxh5i9HARjevjr/7d0ATzcHdFtOiYcdc+3LzYbc/v4Ki8YDoMUw+/Lip+DMFnPziEiBUcEikg9iElLo/eF6Vu6JxsPVhUm9GzC8fQ0sjmp3sWMupCdBUASEtXHMPguLe8dD9Y6QkQJfPQLxZ8xOJCIFQAWLiIPtO5dA92m/sfN0PCV93JkzuDndG5Z33AEM48/bQU0fL36NT11c7Y1uy9aGy1HwVR9ISzI7lYjkMxUsIg7084EYes5Yz9n4FKqW8WXR061oGlbKsQc5thbiDoKHP0T2cey+CwuvAOg7F3zKQNROWPQE2GxmpxKRfKSCRcRBPl9/nH9+uonLqRncUbUUC59uSVgZX8cfaONH9n8j+4BnMZ4gsWRl6PMluHrAvqXw0xtmJxKRfKSCReQ2WW0Gry/dw2vf7sFmQI/GFfj8seaU8HFAT6C/u3QKDnxnX276uOP3X9hUag73T7Uvr5v4Z0NkESlyNHCcyG1ISs3g2a+2sXp/DAAvdqzJ0+3CHde49u82fwKGDaq0hbIR+XOMwiayN8QdgF/fhyXP2OcbqnSH2alExMF0hUXkFp2Lv0LPGetZvT8GTzcXpj3SiKF3Vcu/YiUjFbZ+bl9uOjh/jlFY3fUq1LofrGkwtx9cPGF2IhFxMBUsIrdg95l4uk/7jb3nEijj58FXQ+6gS/2Q/D3onsWQHAcB5aFm5/w9VmHj4gIPzoCQSPtr9GVvSEkwO5WIOJAKFpE8WrU3mp4z1hOdkEr1sn4seroVjSqVzP8Db/zQ/m+TQeCqu7k5ePjaew75lYPYfbDgn2Czmp1KRBxEBYvITTIMg//79ShDZm/mSrqVNtXLsODpllQs5ZP/Bz+7zT7xn4s7NBqQ/8crrAJCoe9X4OYNh36AH4rwhJAixYwKFpGbkGG1Mebb3by5fB+GAX2bVeKTgU0J8HIvmAAbrw4UV6c7+JUtmGMWVuUbwYPT7ct/TIMtn5oaR0QcQ9eVRW4gMSWdoV9u45eDsVgs8K9OtXi8TZX8a1z7d8kX7DMUQ/GaN+h21HkQ4g7ZJ0lc/gKUqmrvWSUihZausIhcx+mLyfSYvp5fDsbi7e7KjEcbM7ht1YIrVgC2zbbPm1OuPlRoWnDHLezavgj1eoItA+b9A84fMTuRiNwGFSwi17D91CW6T/udA9GJlPX3ZP4TLehYp1zBhrBZYdPH9uVmg4vfvEG3w2KxDypXoSmkXIIve8GVi2anEpFbpIJFJBff7zpHnw/XE3c5lYhy/iwe2op6FQILPsihVXDpBHiVgLo9Cv74hZ27l334/oAKcP4wzB8A1nSzU4nILVDBIvIXhmEwY+0RnpqzlZR0G3fVDOKbp1oSWsLbnECbrs4b1PBR8CiA3khFkV9ZeGQeuPvaJ478/iX7jNciUqioYBG5Kt1qY9SCXfz7+/0ADGhRmY/6N8HP06S26eePwOEfAQs0/ac5GYqKcnWhx8eAxT69QeaYNiJSaKhgEQHik9MZ8MlG5m0+hYsFxnWrzesP1MXN1cT/IpltV6rfa+/lIrenZie4d7x9ecUoOPSjuXlEJE9UsEixd/J8Mg9N/43fj5zH18OV/xvQhIGtqpgbKi0Jtn9hX9a8QY7T8hlo8Kh9AslvBkHMfrMTichNUsEixdqWExfo/sFvHIlNIiTQi6+fbMndEcFmx4JdX0NKvH3m4WrtzU5TdFgs0PW/ULkVpCbAV70h6bzZqUTkJqhgkWJryY6z9P1oAxeS0qhbPoDFQ1tROzTA7Fj2BqGZI9s2fdw+sZ84jpsH9JptLwYvHod5j9pnwhYRp6ZPQil2DMNgyupDPPvVNtIybNxbO5j5T7QgOMDL7Gh2pzZA9C5w84IG/cxOUzT5loZH5oNnAJz8HZY9r55DIk5OBYsUK6kZVl6Yv4P3Vx0EYHCbKsx4tDE+Hk40S0VmD5Z6PcGnlLlZirKgmtBzFlhcYPsc+P1/ZicSketQwSLFxsWkNP7x8UYWbjuDq4uFN7vX5ZUutXF1caLRYxOjYe8S+3IzNbbNd9Xaw33v2JdXjYX935mbR0SuSQWLFAtHYy/z4Ae/sfHYBfw93Zg1sCmP3lHZ7Fg5bf0MbOlQoRmERJqdpnhoPsTeVggDFjwO53aanUhEcqGCRYq8DUfP89D03zl+PpnyJbz55qmWtK0RZHasnKzp9kHNQLMyF7T7/g1V20F6EnzV136lS0ScigoWKdLOXrpC/082cik5nQYVS7B4aCtqlvM3O1bu9i+HxHPgGwS17zc7TfHi6g49P4PS1SHhNMx9BNKvmJ1KRP5CBYsUaUt2nCU1w0b9CoHMHXIHQf6eZke6to1X5w1qNADcnDhnUeVdwj7nkHdJOLMZvh2mnkMiTkQFixRpS3ecBaBP00p4ubuanOY6ovfCiXVgcYUmg8xOU3yVDreP0eLiBru/gbXvmp1IRK5SwSJF1pHYy+w5m4Cbi4X76pYzO871bbo6UFxEZwisYG6W4q5KG+gy0b685m3YvdDcPCICqGCRImzZjnMAtK5ehlK+HianuY6UeNgx176sxrbOofEAaDHMvrz4KTizxdw8IqKCRYomwzBYsuMMAPdHhpqc5gZ2zLX3TgmKgLA2ZqeRTPeOh+odISMFvnoE4s+YnUikWLulgmXatGmEhYXh5eVF8+bN2bhx4zW3TU9PZ/z48YSHh+Pl5UVkZCQrVqzIsd2ZM2d49NFHKV26NN7e3tSrV4/NmzffSjwR9p1L5EhsEh5uLtxb2wkmM7wWw/izsW3Tx+2T84lzcHGFh/8PytaGy1HwVR/7LNoiYoo8Fyzz5s1jxIgRjB07lq1btxIZGUnHjh2JiYnJdftXX32VmTNnMmXKFPbu3cuTTz7Jgw8+yLZt27K2uXjxIq1atcLd3Z3vv/+evXv38v7771OyZMlbPzMp1pbutDe2vbtmWfy93E1Ocx1H18D5Q+DhD5F9zE4jf+cVAH3ngk8ZiNoJi54Am83sVCLFksUw8tZvr3nz5jRt2pSpU6cCYLPZqFixIs888wyjRo3KsX1oaCivvPIKQ4cOzVr38MMP4+3tzRdffAHAqFGj+O233/j1119v+UQSEhIIDAwkPj6egAAnmHFXTGMYBm3e/ZnTF68w7ZFGdKkfYnaka5vbD/Yvg6aDoct7ZqeRazm5AT7rCtY0aD0C2o81O5FIkXGzv7/zdIUlLS2NLVu20L59+z934OJC+/btWb9+fa7PSU1Nxcsr+yy43t7erFu3Luv7JUuW0KRJE3r27EnZsmVp2LAhH3300XWzpKamkpCQkO1LBGD7qUucvngFXw9X7o4oa3aca7t0Cg5cnbum6ePmZpHrq9Qc7rf/kca6ibD9K3PziBRDeSpY4uLisFqtBAdnbxMQHBxMVFRUrs/p2LEjEydO5NChQ9hsNlatWsXChQs5d+5c1jZHjx5l+vTpVK9enZUrV/LUU0/x7LPP8tlnn10zy4QJEwgMDMz6qlixYl5ORYqwJVfHXrm3djDeHk489srmT8CwQZW2UDbC7DRyI5G9oc0L9uWlz8LJP8zNI1LM5HsvocmTJ1O9enUiIiLw8PBg2LBhDBo0CBeXPw9ts9lo1KgRb7/9Ng0bNmTIkCEMHjyYGTNmXHO/o0ePJj4+Puvr1KlT+X0qUghYbQbLd9qL4W7O3DsoIxW2fm5fbqpZmQuNu16FWvfbbw3N7QcXT5idSKTYyFPBUqZMGVxdXYmOzj4xWHR0NOXK5T4wV1BQEIsXLyYpKYkTJ06wf/9+/Pz8qFq1atY2ISEh1K5dO9vzatWqxcmTJ6+ZxdPTk4CAgGxfIhuPXSAmMZUALzfaVHfCCQ4z7VkMyXEQUB5qdjY7jdwsFxd4cIZ9Ju3kOPiyN6TodrRIQchTweLh4UHjxo1ZvXp11jqbzcbq1atp0aLFdZ/r5eVF+fLlycjIYMGCBTzwwANZj7Vq1YoDBw5k2/7gwYNUrlw5L/FEsnoHdaobgoebEw8ztPFD+79NBoGrm7lZJG88fO09h/zKQew+WPBPsFnNTiVS5OX5E33EiBF89NFHfPbZZ+zbt4+nnnqKpKQkBg2yz3/Sv39/Ro8enbX9hg0bWLhwIUePHuXXX3/lvvvuw2az8dJLL2Vt8/zzz/PHH3/w9ttvc/jwYb788ks+/PDDbD2LRG4k3Wrj+12F4HbQma32yfVc3O0THUrhExAKfb8CN2849AP8MMbsRCJFXp7/tOvduzexsbG89tprREVF0aBBA1asWJHVEPfkyZPZ2qekpKTw6quvcvToUfz8/OjcuTOzZ8+mRIkSWds0bdqURYsWMXr0aMaPH0+VKlWYNGkS/fr1u/0zlGJj3eE4LianU8bPkxbhpc2Oc22Z8wbV6Q5+TtyLSa6vfCP77aGvB8Af0yCoBjQeaHYqkSIrz+OwOCuNwyIj5m9n4dYzDGhRmdcfqGt2nNwlX4CJtezDvf9zFVRsZnYiuV1r/wM/v2mf4fkfi+y9vkTkpuXLOCwiziol3coPe+yNwZ36dtC22fZipVx9qNDU7DTiCG1HQr2eYMuAef+A80fMTiRSJKlgkSJhzYFYLqdmEBroRaNKTjqlg8365+2gZoM1b1BRYbHYB5Wr0BRSLsGXveDKRbNTiRQ5KlikSMjsHdQ1MhQXFyctBA6tgksnwasE1O1hdhpxJHcv6PMlBFSA84dh/gCwppudSqRIUcEihV5Sagar99lvB93vzLeDNl2dbqLho+DhY24WcTy/svDIPHD3hWNr4fuX7LNxi4hDqGCRQu/HfdGkpNuoUsaXOqFO2uD6/BE4/CNggab/NDuN5JdydaHHx4DFPvVC5ng7InLbVLBIobf06txB3eqHYHHWdiGbPrb/W/1eKFX1+ttK4VazE9w73r68YhQc+tHcPCJFhAoWKdTik9NZezAWcOLeQWlJsP0L+7LmDSoeWj5jv/Vn2OCbQRCz3+xEIoWeChYp1FbuiSLdahBRzp/qwf5mx8ndrq8hJR5KhkG19mankYJgsUCX/0LlVpCaYO85lHTe7FQihZoKFinUlmTeDnLWqyuGARuvdmVu+rh98jwpHtw8oNdse6F66QTMe9Q+S7eI3BJ9ekqhFZuYyu9H4gDoVt9JC5aTf0D0LnDzggaaaqLY8S0Nj8wHzwA4+Tsse149h0RukQoWKbS+330OmwGRFUtQqbSTdhPO7Mpcryf4lDI3i5gjqCb0nAUWF9g+B37/n9mJRAolFSxSaP21d5BTSoyCvd/al5upsW2xVq093PeOfXnVWNj/nbl5RAohFSxSKJ29dIVNxy9isUBXZ70dtOUz+/wyFZpBSKTZacRszYfY2zFhwILH4dxOsxOJFCoqWKRQWnZ1KP6mYaUoF+hlcppcWNNhyyz7crMh5mYR53HfO1C1HaQnwVd9ITHa7EQihYYKFimUlu44BzjxUPz7l0PiOfANgtr3m51GnIWrG/T8DEpXh4TTMPcRSL9idiqRQkEFixQ6x+KS2HUmHlcXC53qljM7Tu42Xm1s22gAuHmam0Wci3cJ+5xD3iXhzGb4dph6DoncBBUsUugsu9rYtlW1MpT2c8JiIHovnFgHFldoMsjsNOKMSofbx2hxcYPd38Dad81OJOL03MwOIJJXS3c6ee+gTVcHiovoDIEVzM0izqtKG+gyEZY+C2vetnd7LlHR7FQi11f7AXD3NuXQKlikUNkflcDB6Mt4uLrQoY4T3g5KiYcdc+3LamwrN9J4AMQdhPVT4ec3zU4jcmNV71LBInIzMsdeaVcziEBvd5PT5GLHXHsPkKAICGtjdhopDO4dD57+cGqj2UlEbszVvM9dFSxSaBiGkdU7yCnnDjKMPxvbNn3cPgGeyI24uEK7UWanEHF6anQrhcbO0/GcvJCMt7sr99Qqa3acnI6ugfOHwMMfIvuYnUZEpEhRwSKFRubtoPa1g/HxcMKLg5mNbSP72C/xi4iIw6hgkULBZjNYtvPq7SBn7B106RQcuDo/TNPHzc0iIlIEqWCRQmHT8QtEJaTg7+XGnTWDzI6T0+ZPwLBBlbZQNsLsNCIiRY4KFikUMsdeua9OOTzdXE1O8zfpKbD1M/tyU83KLCKSH1SwiNPLsNr4blcU4KS9g/YuhuTzEFAeanY2O42ISJGkgkWc3u9HznMhKY1Svh60DC9tdpycMrsyNxlkn9xOREQcTgWLOL0lV3sHda5XDjdXJ3vLntlqn8DOxd0+0aGIiOQLJ/v0F8kuNcPKyt1XbwfVd8LbQZldmet0Bz8nHBtGRKSIUMEiTm3tgVgSUzMoF+BF07BSZsfJLvkC7PrGvqx5g0RE8pUKFnFqS6+OvdK1fgguLk421P3Wz8GaCuXqQ4WmZqcRESnSVLCI00pOy+DHvdGAE/YOsllh88f25WaDNW+QiEg+U8EiTmv1vhiupFupVMqH+hUCzY6T3aFVcOkkeJWAuj3MTiMiUuSpYBGnldk7qFtkCBZnu4Kx8UP7vw0fBQ8fc7OIiBQDKljEKcVfSWftgVgA7o8sb3Kavzl/BI6sBizQ9J9mpxERKRZUsIhT+mFPFGlWGzWC/ahZzslmPt50te1K9XuhVFVzs4iIFBMqWMQpLc2amdnJGtumJcG2L+zLmjdIRKTAqGARp3P+ciq/HY4DoKuz9Q7a9TWkxkPJMKjW3uw0IiLFhgoWcTrf7Y7CajOoVz6QKmV8zY7zJ8OAjVdHtm36OLjov4+ISEHRJ644naVXewfd72xXV07+AdG7wM0LGvQzO42ISLGigkWcyrn4K2w6fgGALvVDTE7zN5uuzspcryf4ONk0ASIiRZwKFnEqy3eewzCgaVhJQkt4mx3nT4lRsPdb+3IzNbYVESloKljEqWT1DnK220FbPgNbBlRoBiGRZqcRESl2VLCI0zhxPokdpy7hYoFOdZ3odpA1HbbMsi9rVmYREVOoYBGnsezq1ZWW4WUI8vc0Oc1f7F8GiefANwhq3292GhGRYkkFizgNp+0dlNmVudEAcHOiQkpEpBhRwSJO4WB0IvujEnF3tdCxTjmz4/wpei+cWAcWV2gyyOw0IiLFlgoWcQrLrl5dubNGEIE+7ian+YvMrswRnSGwgrlZRESKMRUsYjrDMFhytWBxqt5BKfGwY559WY1tRURMpYJFTLf7TALHzyfj5e5C+1rBZsf50465kJ4EQREQ1sbsNCIixZoKFjHd0p32qyv31ArG19PN5DRXGQZsvHo7qOnjYLGYm0dEpJhTwSKmstmMrPYr3eo70e2go2vg/CHw8IfIPmanEREp9lSwiKm2nrzI2fgU/DzdaFczyOw4f8q8uhLZBzz9zc0iIiIqWMRcmY1tO9QJxsvd1eQ0V106BQe/ty83fdzcLCIiAqhgERNlWG18t8sJ5w7a/AkYNqjSFspGmJ1GRERQwSIm+uPoBeIup1HSx53W1cqYHccuPQW2fmZfbqpZmUVEnIUKFjFN5lD8neqF4O7qJG/FvYsh+TwElIeanc1OIyIiVznJbwkpbtIybHy/++rtIGfqHZTZ2LbJIHB1ki7WIiKigkXM8cvBWBJSMijr70mzKqXMjmN3Ziuc2Qwu7vaJDkVExGmoYBFTZA4W16V+CK4uTjIo26arszLX6Q5+ZU2NIiIi2algkQJ3Jc3Kqr3RANzvLL2Dki/Arm/sy5o3SETE6ahgkQL30/4YktOsVCjpTYOKJcyOY7f1c7CmQrn6UKGp2WlERORvVLBIgVv6l5mZLc4wR4/NCps/ti83G6x5g0REnJAKFilQCSnp/HQgBnCi3kGHfoBLJ8GrBNTtYXYaERHJxS0VLNOmTSMsLAwvLy+aN2/Oxo0br7lteno648ePJzw8HC8vLyIjI1mxYsU1t//3v/+NxWJh+PDhtxJNnNyqPdGkZdgID/KlVoiTzNGT2ZW54aPg4WNuFhERyVWeC5Z58+YxYsQIxo4dy9atW4mMjKRjx47ExMTkuv2rr77KzJkzmTJlCnv37uXJJ5/kwQcfZNu2bTm23bRpEzNnzqR+/fp5PxMpFDJ7BznN7aDzR+DIasACTf9pdhoREbmGPBcsEydOZPDgwQwaNIjatWszY8YMfHx8+OSTT3Ldfvbs2fzrX/+ic+fOVK1alaeeeorOnTvz/vvvZ9vu8uXL9OvXj48++oiSJUve2tmIU7uQlMa6Q3GAE80dlNmVufq9UKqquVlEROSa8lSwpKWlsWXLFtq3b//nDlxcaN++PevXr8/1OampqXh5eWVb5+3tzbp167KtGzp0KF26dMm27+tJTU0lISEh25c4txW7o8iwGdQJDSA8yM/sOJCWBNvm2Jc1b5CIiFPLU8ESFxeH1WolODg42/rg4GCioqJyfU7Hjh2ZOHEihw4dwmazsWrVKhYuXMi5c+eytpk7dy5bt25lwoQJN51lwoQJBAYGZn1VrFgxL6ciJliy4wzgRFdXdn0NqfFQMgyq3VyhLCIi5sj3XkKTJ0+mevXqRERE4OHhwbBhwxg0aBAuLvZDnzp1iueee445c+bkuBJzPaNHjyY+Pj7r69SpU/l1CuIA0QkpbDh2AYAu9UJMTgMYxp+NbZs+Di7qMCci4szy9CldpkwZXF1diY6OzrY+OjqacuXK5fqcoKAgFi9eTFJSEidOnGD//v34+flRtaq9vcCWLVuIiYmhUaNGuLm54ebmxtq1a/nf//6Hm5sbVqs11/16enoSEBCQ7Uuc1/Kd5zAMaFSpBBVLOUFPnJN/QPRucPOCBv3MTiMiIjeQp4LFw8ODxo0bs3r16qx1NpuN1atX06JFi+s+18vLi/Lly5ORkcGCBQt44IEHALjnnnvYtWsX27dvz/pq0qQJ/fr1Y/v27bi6ut7CaYmzyewd5DRD8W+6enWlXk/wcZLJF0VE5Jrc8vqEESNGMGDAAJo0aUKzZs2YNGkSSUlJDBo0CID+/ftTvnz5rPYoGzZs4MyZMzRo0IAzZ84wbtw4bDYbL730EgD+/v7UrVs32zF8fX0pXbp0jvVSOJ26kMy2k5dwsUDn+k5wOygxCvZ+a19upsa2IiKFQZ4Llt69exMbG8trr71GVFQUDRo0YMWKFVkNcU+ePJnVPgUgJSWFV199laNHj+Ln50fnzp2ZPXs2JUqUcNhJiHPLvLpyR9XSlPW/+XZK+WbLZ2DLgArNICTS7DQiInITLIZhGGaHcISEhAQCAwOJj49XexYn02nyr+w7l8CEh+rRt1klc8NY0+G/deFyFDz0f1C/p7l5RESKuZv9/a2uEZKvDscksu9cAm4uFu6rk3vD7AK1f5m9WPENgtr3m51GRERukgoWyVdLd9jH22lbI4iSvh4mpwE2Xh3ZttEAcPM0N4uIiNw0FSySbwzD+MvcQU7Q2DZ6D5xYBxZXaDLI7DQiIpIHKlgk3+w5m8DR2CQ83VxoXyv4xk/Ib5nzBkV0hsAK5mYREZE8UcEi+Sbz6srdEWXx93I3N0xKPOyYZ19uNsTcLCIikmcqWCRfGIbBsqvtV5xi7qDtX0F6EgRFQFgbs9OIiEgeqWCRfLH15CXOXLqCr4crd0eUNTeMYfx5O6jp42CxmJtHRETyTAWL5IulO+y3gzrUKYeXu8nTKxxdA+cPgYc/RPYxN4uIiNwSFSzicFabwfJdmbeDnKB3UOaszJF9wNPf3CwiInJLVLCIw204ep7YxFQCvd1pXS3I3DCxB+Hg9/blpo+bm0VERG6ZChZxuMzeQZ3qlsPDzcS3mM0Gy4aDYYManaBshHlZRETktqhgEYdKy7Dx/e4owAl6B23/Ak78Bu4+0Okdc7OIiMhtUcEiDvXb4TguJadTxs+TO6qWNi/I5Vj4YYx9+a5/QcnK5mUREZHbpoJFHGrJ1d5BXeuH4OpiYvfhlaMh5RKUqw/NnzIvh4iIOIQKFnGYlHQrP+zJvB1kYu+gwz/Crq/B4gLdJoOrm3lZRETEIVSwiMP8vD+GpDQr5Ut407BiSXNCpCXDshH25WZPQPlG5uQQERGHUsEiDpPZO6hr/RBczLodtPYduHQCAsrD3a+Yk0FERBxOBYs4xOXUDFbviwFM7B0UtRt+n2Jf7vyeBokTESlCVLCIQ6zaG0Vqho2qZXypExpQ8AFsVlj6HBhWqNUNIjoXfAYREck3KljEIZZenZm5a2QoFjMmF9z8CZzZbJ8vqNO7BX98ERHJVypY5LZdSk7jl4OxAHSrb0LvoISz8OPr9uX2YyHA5AHrRETE4VSwyG1bsTuKDJtBRDl/qgeb0G7k+5cgLRHKN4EmjxX88UVEJN+pYJHbltk76P4GJlzZ2P8d7FsKLm72MVdcXAs+g4iI5DsVLHJbYhJTWH/kPADd6hdwwZKaCN+NtC+3GAbl6hbs8UVEpMCoYJHb8t3Oc9gMaFCxBBVL+RTswX96CxLOQInKcOfLBXtsEREpUCpY5LYs3WnvHVTgY6+c2QIbZtiXu/4XPAq4WBIRkQKlgkVu2emLyWw5cRGLxT66bYGxZtjHXMGAej2h2j0Fd2wRETGFCha5ZcuvXl1pXqUUwQFeBXfgPz6AqF3gVQI6Tii444qIiGlUsMgtW7LD3juoQG8HXTwBa64WKR3eAL+ggju2iIiYRgWL3JIjsZfZczYBVxcLneoW0O0gw4DlL0B6MlRuDQ3/UTDHFRER06lgkVuy7OpQ/K2rlaGUr0fBHHTPQji8Clw9oNskMGMKABERMYUKFskzwzBYsuMMUIC3g65chO9H2ZfbvABlqhfMcUVExCmoYJE82x+VyJHYJDzcXOhQJ7hgDvrjOEiKgTI1oPXzBXNMERFxGipYJM8yG9veVTOIAC/3/D/gifWw5VP7ctdJ4OaZ/8cUERGnooJF8sQwDJYWZO+gjDRYNty+3PAfENYq/48pIiJORwWL5Mn2U5c4ffEKPh6u3B1RNv8P+NtkiN0PvkFw7/j8P56IiDglFSySJ0uv9g5qXysYHw+3/D1Y3GH45T/25Y4TwKdU/h5PRESclgoWuWlWm8GynQV0O8gw7LeCrKkQfjfU65G/xxMREaemgkVu2sZjF4hJTCXAy422Ncrk78F2fAXHfwU3b+gyUWOuiIgUcypY5KYtvXp15b665fB0c82/AyWdh5Wv2JfbvQylquTfsUREpFBQwSI3Jd1q4/td9vYr+X476IdX4MoFCK4LLYbl77FERKRQUMEiN+W3w3FcTE6ntK8HLaqWzr8DHV1jvx2EBbpNBtcCGOdFREScngoWuSmZvYM61wvBzTWf3jbpV2DZ1VFsmz4OFZrkz3FERKTQUcEiN5SSbuWHPVEA3N8gH28H/fIeXDgK/iFwz2v5dxwRESl0VLDIDa05EEtiagYhgV40rlQyfw4Ssw9+m2Rf7vQueAXkz3FERKRQUsEiN5TZO6hr/RBcXPKhe7HNBkufA1sG1OwMtbo5/hgiIlKoqWCR60pKzWD1vmggH3sHbf0UTm0ADz/o/B+NuSIiIjmoYJHr+nFfNCnpNiqX9qFe+UDHHyAxClaNsy/f/SoEVnD8MUREpNBTwSLXlTkz8/2RoVjy48rHilGQGg+hDaHZEMfvX0REigQVLHJN8cnprD0YC+TT7aCDP8CeRWBxtY+54pKPo+eKiEihpoJFrmnlnijSrQY1g/2pEezv2J2nJcHyF+zLdzwFIZGO3b+IiBQpKljkmpZmzcwc4vid//w2xJ+EwEpw178cv38RESlSVLBIruIup/Lb4TgAutZ38O2gczvgj+n25S7vg4evY/cvIiJFjgoWydV3u85hM6B+hUDCyjiwoLBZYcmzYFihzkNQo4Pj9i0iIkWWChbJ1V97BznUhplwbjt4BcJ9/3bsvkVEpMhSwSI5nL10hU3HLwLQpb4D269cOgU/vWlfbv86+Ac7bt8iIlKkqWCRHJbvtM/M3CysFCGB3o7ZqWHAdy9CehJUvAMaDXDMfkVEpFhQwSI55EvvoH1L4OD34OJ+dcwVvfVEROTm6beGZHM8Lomdp+NxdbHQqZ6DCpaUePjuJfty6+FQNsIx+xURkWJDBYtkk9nYtmV4acr4eTpmp6vHw+UoKBUObUY6Zp8iIlKsqGCRbP68HeSg3kGnNsKmj+3LXf8L7l6O2a+IiBQrKlgky4GoRA5GX8bd1ULHOuVuf4fWdFj6HGBA5CNQ9c7b36eIiBRLKlgkS+btoDtrlCXQ2/32d/j7FIjZC96loMObt78/EREptlSwCACGYTi2d9CFo7D2Hftyx7fBt/Tt71NERIotFSwCwM7T8Zw4n4y3uyv31r7NAd0MA5aNgIwUqHInRPZxTEgRESm2VLAI8OftoHtqlcXHw+32drbrazj6M7h62hvaWiwOSCgiIsXZLRUs06ZNIywsDC8vL5o3b87GjRuvuW16ejrjx48nPDwcLy8vIiMjWbFiRbZtJkyYQNOmTfH396ds2bJ0796dAwcO3Eo0uQU2m8Gyq6Pb3nbvoOQLsGK0ffnOF6F0+G2mExERuYWCZd68eYwYMYKxY8eydetWIiMj6dixIzExMblu/+qrrzJz5kymTJnC3r17efLJJ3nwwQfZtm1b1jZr165l6NCh/PHHH6xatYr09HQ6dOhAUlLSrZ+Z3LTNJy4SlZCCv6cbd9YIur2drRoDyXEQVAtaPueYgCIiUuxZDMMw8vKE5s2b07RpU6ZOnQqAzWajYsWKPPPMM4waNSrH9qGhobzyyisMHTo0a93DDz+Mt7c3X3zxRa7HiI2NpWzZsqxdu5a2bdveVK6EhAQCAwOJj48nICAgL6dU7I1ZvJvZf5zg4UYVeL9X5K3v6Pg6+LSLffmxlVDpDscEFBGRIutmf3/n6QpLWloaW7ZsoX379n/uwMWF9u3bs379+lyfk5qaipdX9sHCvL29Wbdu3TWPEx8fD0CpUqWuuU1qaioJCQnZviTvMqw2vttlvx10f4PbuB2UkQpLh9uXGw9SsSIiIg6Vp9aVcXFxWK1WgoOz9yIJDg5m//79uT6nY8eOTJw4kbZt2xIeHs7q1atZuHAhVqs11+1tNhvDhw+nVatW1K1b95pZJkyYwOuvv56X+Ldkwvf7SEzJyPfjmCU+OZ3zSWmU8vWgZfhtdD3+dSKcPwR+wdB+nMPyiYiIQB4LllsxefJkBg8eTEREBBaLhfDwcAYNGsQnn3yS6/ZDhw5l9+7d170CAzB69GhGjBiR9X1CQgIVK1Z0aHaARVvPEJOY6vD9Opsu9UJwd73FTmOxB2HdRPvyff8G7xIOyyUiIgJ5LFjKlCmDq6sr0dHR2dZHR0dTrlzuQ7kHBQWxePFiUlJSOH/+PKGhoYwaNYqqVavm2HbYsGEsW7aMX375hQoVKlw3i6enJ56eDpqc7zqGtK1KUmruV4OKCm8PF3o1ucViz2aDZcPBmgbVO0CdBx2aTUREBPJYsHh4eNC4cWNWr15N9+7dAfstnNWrVzNs2LDrPtfLy4vy5cuTnp7OggUL6NWrV9ZjhmHwzDPPsGjRItasWUOVKlXyfib55PE2OQsr+YvtX8CJ38DdBzq/pzFXREQkX+T5ltCIESMYMGAATZo0oVmzZkyaNImkpCQGDRoEQP/+/SlfvjwTJkwAYMOGDZw5c4YGDRpw5swZxo0bh81m46WXXsra59ChQ/nyyy/59ttv8ff3JyoqCoDAwEC8vb0dcZ6SHy7Hwg9j7Mt3/QtKVjY3j4iIFFl5Llh69+5NbGwsr732GlFRUTRo0IAVK1ZkNcQ9efIkLi5/toVISUnh1Vdf5ejRo/j5+dG5c2dmz55NiRIlsraZPn06AO3atct2rFmzZjFw4MC8n5UUjJWjIeUSlKsPzZ8yO42IiBRheR6HxVlpHJYCdvhH+OJhsLjA46uhfCOzE4mISCGUL+OwiACQlmyf3BCg+ZMqVkREJN+pYJG8W/sOXDoBARXgrlfMTiMiIsWAChbJm6jd8PsU+3KX98DTz9w8IiJSLKhgkZtns8LS58CwQq37oWYnsxOJiEgxoYJFbt7mT+DMZvAMgE7vmp1GRESKERUscnMSzsKPV+duuuc1CAgxN4+IiBQrKljk5nz3IqQlQoWm0OSfZqcREZFiRgWL3Nj+5bB/Gbi4QbfJ4KK3jYiIFCz95pHrS020X10BaPkMBNcxN4+IiBRLKljk+n56ExLOQMkwuPNls9OIiEgxpYJFru3MFtgw077c9b/grokoRUTEHCpYJHfWDPuYKxhQrxeE3212IhERKcZUsEju/vgAonaBd0no+LbZaUREpJhTwSI5XTwBaybYl+99A/yCzM0jIiLFngoWyc4wYPkLkJ4MlVtDw0fNTiQiIqKCRf5mz0I4vApcPaDbJLBYzE4kIiKigkX+4spF+H6UfbnNC1Cmurl5RERErlLBIn/6cRwkxUCZGtD6ebPTiIiIZFHBInYn1sOWT+3LXSeBm6eZaURERLJRwSKQkQbLhtuXG/4DwlqZGkdEROTvVLAI/DYZYveDbxDcO97sNCIiIjm4mR3A6f30ln0CwKLKsP15K6jjBPApZWocERGR3KhguZGtn8PlKLNT5L/wu6FeD7NTiIiI5EoFy400fwLSLpudIn+5eUHjQRpzRUREnJYKlhtpM8LsBCIiIsWeGt2KiIiI01PBIiIiIk5PBYuIiIg4PRUsIiIi4vRUsIiIiIjTU8EiIiIiTk8Fi4iIiDg9FSwiIiLi9FSwiIiIiNNTwSIiIiJOTwWLiIiIOD0VLCIiIuL0VLCIiIiI0ysyszUbhgFAQkKCyUlERETkZmX+3s78PX4tRaZgSUxMBKBixYomJxEREZG8SkxMJDAw8JqPW4wblTSFhM1m4+zZs/j7+2OxWBy234SEBCpWrMipU6cICAhw2H6dSVE/R51f4VfUz1HnV/gV9XPMz/MzDIPExERCQ0Nxcbl2S5Uic4XFxcWFChUq5Nv+AwICiuSb8K+K+jnq/Aq/on6OOr/Cr6ifY36d3/WurGRSo1sRERFxeipYRERExOmpYLkBT09Pxo4di6enp9lR8k1RP0edX+FX1M9R51f4FfVzdIbzKzKNbkVERKTo0hUWERERcXoqWERERMTpqWARERERp6eCRURERJyeChYRERFxeipYbmDatGmEhYXh5eVF8+bN2bhxo9mRHOaXX36hW7duhIaGYrFYWLx4sdmRHGbChAk0bdoUf39/ypYtS/fu3Tlw4IDZsRxq+vTp1K9fP2vkyRYtWvD999+bHSvf/Pvf/8ZisTB8+HCzozjMuHHjsFgs2b4iIiLMjuVQZ86c4dFHH6V06dJ4e3tTr149Nm/ebHYshwgLC8vx87NYLAwdOtTsaA5jtVoZM2YMVapUwdvbm/DwcN54440bTlSYH1SwXMe8efMYMWIEY8eOZevWrURGRtKxY0diYmLMjuYQSUlJREZGMm3aNLOjONzatWsZOnQof/zxB6tWrSI9PZ0OHTqQlJRkdjSHqVChAv/+97/ZsmULmzdv5u677+aBBx5gz549ZkdzuE2bNjFz5kzq169vdhSHq1OnDufOncv6WrdundmRHObixYu0atUKd3d3vv/+e/bu3cv7779PyZIlzY7mEJs2bcr2s1u1ahUAPXv2NDmZ47zzzjtMnz6dqVOnsm/fPt555x3effddpkyZUvBhDLmmZs2aGUOHDs363mq1GqGhocaECRNMTJU/AGPRokVmx8g3MTExBmCsXbvW7Cj5qmTJksb//d//mR3DoRITE43q1asbq1atMu68807jueeeMzuSw4wdO9aIjIw0O0a+efnll43WrVubHaPAPPfcc0Z4eLhhs9nMjuIwXbp0MR577LFs6x566CGjX79+BZ5FV1iuIS0tjS1bttC+ffusdS4uLrRv357169ebmExuRXx8PAClSpUyOUn+sFqtzJ07l6SkJFq0aGF2HIcaOnQoXbp0yfZ/sSg5dOgQoaGhVK1alX79+nHy5EmzIznMkiVLaNKkCT179qRs2bI0bNiQjz76yOxY+SItLY0vvviCxx57DIvFYnYch2nZsiWrV6/m4MGDAOzYsYN169bRqVOnAs9SZGZrdrS4uDisVivBwcHZ1gcHB7N//36TUsmtsNlsDB8+nFatWlG3bl2z4zjUrl27aNGiBSkpKfj5+bFo0SJq165tdiyHmTt3Llu3bmXTpk1mR8kXzZs359NPP6VmzZqcO3eO119/nTZt2rB79278/f3Njnfbjh49yvTp0xkxYgT/+te/2LRpE88++yweHh4MGDDA7HgOtXjxYi5dusTAgQPNjuJQo0aNIiEhgYiICFxdXbFarbz11lv069evwLOoYJEib+jQoezevbtItQ3IVLNmTbZv3058fDzffPMNAwYMYO3atUWiaDl16hTPPfccq1atwsvLy+w4+eKvf6XWr1+f5s2bU7lyZebPn88///lPE5M5hs1mo0mTJrz99tsANGzYkN27dzNjxowiV7B8/PHHdOrUidDQULOjONT8+fOZM2cOX375JXXq1GH79u0MHz6c0NDQAv8ZqmC5hjJlyuDq6kp0dHS29dHR0ZQrV86kVJJXw4YNY9myZfzyyy9UqFDB7DgO5+HhQbVq1QBo3LgxmzZtYvLkycycOdPkZLdvy5YtxMTE0KhRo6x1VquVX375halTp5Kamoqrq6uJCR2vRIkS1KhRg8OHD5sdxSFCQkJyFM+1atViwYIFJiXKHydOnODHH39k4cKFZkdxuBdffJFRo0bRp08fAOrVq8eJEyeYMGFCgRcsasNyDR4eHjRu3JjVq1dnrbPZbKxevbrItREoigzDYNiwYSxatIiffvqJKlWqmB2pQNhsNlJTU82O4RD33HMPu3btYvv27VlfTZo0oV+/fmzfvr3IFSsAly9f5siRI4SEhJgdxSFatWqVYziBgwcPUrlyZZMS5Y9Zs2ZRtmxZunTpYnYUh0tOTsbFJXup4Orqis1mK/AsusJyHSNGjGDAgAE0adKEZs2aMWnSJJKSkhg0aJDZ0Rzi8uXL2f6SO3bsGNu3b6dUqVJUqlTJxGS3b+jQoXz55Zd8++23+Pv7ExUVBUBgYCDe3t4mp3OM0aNH06lTJypVqkRiYiJffvkla9asYeXKlWZHcwh/f/8cbY58fX0pXbp0kWmLNHLkSLp160blypU5e/YsY8eOxdXVlb59+5odzSGef/55WrZsydtvv02vXr3YuHEjH374IR9++KHZ0RzGZrMxa9YsBgwYgJtb0fuV2q1bN9566y0qVapEnTp12LZtGxMnTuSxxx4r+DAF3i+pkJkyZYpRqVIlw8PDw2jWrJnxxx9/mB3JYX7++WcDyPE1YMAAs6PdttzOCzBmzZpldjSHeeyxx4zKlSsbHh4eRlBQkHHPPfcYP/zwg9mx8lVR69bcu3dvIyQkxPDw8DDKly9v9O7d2zh8+LDZsRxq6dKlRt26dQ1PT08jIiLC+PDDD82O5FArV640AOPAgQNmR8kXCQkJxnPPPWdUqlTJ8PLyMqpWrWq88sorRmpqaoFnsRiGCcPViYiIiOSB2rCIiIiI01PBIiIiIk5PBYuIiIg4PRUsIiIi4vRUsIiIiIjTU8EiIiIiTk8Fi4iIiDg9FSwiIiLi9FSwiIiIiNNTwSIiIiJOTwWLiIiIOL3/B4WGcNnpwZV7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| output-location: slide\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "losses = []\n",
    "\n",
    "for depth in range(1, 10):\n",
    "  model = DecisionTreeClassifier(max_depth=depth, criterion=\"entropy\", random_state=34)\n",
    "  model.fit(X_train, y_train)\n",
    "  losses.append([\n",
    "    accuracy_score(y_train, model.predict(X_train)),\n",
    "    accuracy_score(y_test, model.predict(X_test))\n",
    "  ])\n",
    "\n",
    "pd.DataFrame(losses, columns=['train', 'test']).plot(title='Accuracy for different max_depth values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636dd8d",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Different model types have different techniques for dealing with overfitting.\n",
    "\n",
    "One general idea is that instead of training one big model we train a bunch of small models and combine their results somehow.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "The simplest idea along these lines is called **bagging** (bootstrap aggregating). We will use decision trees to illustrate but this works for any model architecture.\n",
    "\n",
    "The idea of bagging is that you train $n$ small decision trees on random subsets of the training data.\n",
    "To generate the final output you then poll the trained decision trees.\n",
    "In case of classification you do a majority vote and in case of regression you take the average.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "Bagging works because of the law of large numbers.\n",
    "\n",
    "For example, suppose you are in a market and you would like to know the weight of a cow but you do not have scales.\n",
    "What you could do is ask a bunch of random people what they think the cow weights and average the result.\n",
    "You will usually get an answer that is very close to the truth.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "For law of large numbers to work you need the predictions of your trained decision trees to be uncorrelated.\n",
    "This will not always be the case, because you are training on the same features.\n",
    "\n",
    "To make the predictions less correlated you can also train the decision trees on a random subset of features and not just on a random subset of the training data.\n",
    "This modelling technique is called **Random Forest**.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "There is also one more general idea called **boosting**.\n",
    "\n",
    "The idea of boosting is that you train a sequence of small models, where when you train the $n$-th model you focus on the mistakes of the previous model.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "To illustrate, we will describe a boosting algorithm called AdaBoost (Adaptive Boosting) in the case of binary classification (for simplicity).\n",
    "\n",
    "Suppose the vectors $(y_i, x_i),$ $i=1, \\dots, m$ represent our training data, where $x_i = (x_{i1}, \\dots, x_{in})$ is a vector.\n",
    "And instead of $y_i$ being either 0 or 1 it is either -1 or 1.\n",
    "If our models predict a positive number we will assign class 1 and otherwise we will assign class -1.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "We will be assigning weights to training samples in each training round of our algorithm.\n",
    "So let $w_i^j$ denote the weight assigned to the $i$-th sample on the $j$-th round.\n",
    "We will always have $\\sum_j w_i^j = 1.$\n",
    "On the first round we assign equal weights $1/m$.\n",
    "\n",
    "Also let $T^j$ denote the tree trained during the $j$-th round.\n",
    "\n",
    "After training compute the weighted classification error:\n",
    "$$\n",
    "e^j = \\sum_i w_i^j \\mathbb{1}_{y_i \\ne T^j(x_i)}.\n",
    "$$\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "Now adjust the weights\n",
    "$$\n",
    "    w^{j+1}_i =  \\begin{cases}\n",
    "       w^{j}_i e^{- \\alpha^j }/Z^j, \\text{ if } T^j(x_i) = y_i, \\\\\n",
    "       w^{j}_i e^{\\alpha^j } / Z^j, \\text{ if } T^j(x_i) \\ne y_i.\n",
    "    \\end{cases},\n",
    "$$\n",
    "where\n",
    "$$\n",
    "    \\alpha^j = \\frac{1}{2} \\ln \\frac{1-e^j}{e^j}\n",
    "$$\n",
    "and $Z^j$ is a number that makes the new weights sum to 1.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "So the weight of a sample increases if the model misclassified it and decreases if the model guessed correctly.\n",
    "\n",
    "The final model is then given by\n",
    "$$\n",
    "    T = \\sum_j \\alpha^j T^j.\n",
    "$$\n",
    "\n",
    "In practice boosting usually results in a more accurate model, but random forrest is faster to train since you can parallelize the training of trees.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "Let's train a Random Forest Regression model on California housing dataset that ships with sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261271dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7067</th>\n",
       "      <td>4.4318</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.721014</td>\n",
       "      <td>1.050725</td>\n",
       "      <td>816.0</td>\n",
       "      <td>2.956522</td>\n",
       "      <td>33.95</td>\n",
       "      <td>-118.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18972</th>\n",
       "      <td>5.2636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.694030</td>\n",
       "      <td>1.279851</td>\n",
       "      <td>872.0</td>\n",
       "      <td>3.253731</td>\n",
       "      <td>38.23</td>\n",
       "      <td>-122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10877</th>\n",
       "      <td>3.9844</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.403042</td>\n",
       "      <td>1.140684</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>4.699620</td>\n",
       "      <td>33.72</td>\n",
       "      <td>-117.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20440</th>\n",
       "      <td>6.4963</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.799038</td>\n",
       "      <td>1.110096</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.221154</td>\n",
       "      <td>34.24</td>\n",
       "      <td>-118.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15424</th>\n",
       "      <td>4.3542</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.578313</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>978.0</td>\n",
       "      <td>2.945783</td>\n",
       "      <td>33.20</td>\n",
       "      <td>-117.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20222</th>\n",
       "      <td>3.5294</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.310962</td>\n",
       "      <td>1.098434</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>2.052573</td>\n",
       "      <td>34.29</td>\n",
       "      <td>-119.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16512</th>\n",
       "      <td>2.6368</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.769022</td>\n",
       "      <td>1.051630</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>3.559783</td>\n",
       "      <td>37.72</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>1.8993</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.699367</td>\n",
       "      <td>1.091772</td>\n",
       "      <td>823.0</td>\n",
       "      <td>2.604430</td>\n",
       "      <td>40.95</td>\n",
       "      <td>-124.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>3.8438</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.422432</td>\n",
       "      <td>1.120545</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>3.670860</td>\n",
       "      <td>34.08</td>\n",
       "      <td>-117.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>2.8000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.553531</td>\n",
       "      <td>0.972665</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>5.446469</td>\n",
       "      <td>34.28</td>\n",
       "      <td>-118.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "7067   4.4318      36.0  5.721014   1.050725       816.0  2.956522     33.95   \n",
       "18972  5.2636       1.0  7.694030   1.279851       872.0  3.253731     38.23   \n",
       "10877  3.9844      38.0  5.403042   1.140684      1236.0  4.699620     33.72   \n",
       "20440  6.4963       6.0  7.799038   1.110096      6700.0  3.221154     34.24   \n",
       "15424  4.3542      34.0  5.578313   0.969880       978.0  2.945783     33.20   \n",
       "20222  3.5294      33.0  4.310962   1.098434      1835.0  2.052573     34.29   \n",
       "16512  2.6368      34.0  5.769022   1.051630      1310.0  3.559783     37.72   \n",
       "2622   1.8993      17.0  4.699367   1.091772       823.0  2.604430     40.95   \n",
       "6033   3.8438      28.0  5.422432   1.120545      3502.0  3.670860     34.08   \n",
       "3421   2.8000      34.0  4.553531   0.972665      2391.0  5.446469     34.28   \n",
       "\n",
       "       Longitude  \n",
       "7067     -118.01  \n",
       "18972    -122.00  \n",
       "10877    -117.88  \n",
       "20440    -118.77  \n",
       "15424    -117.27  \n",
       "20222    -119.29  \n",
       "16512    -121.22  \n",
       "2622     -124.10  \n",
       "6033     -117.73  \n",
       "3421     -118.42  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output-location: slide\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, data[\"target\"], test_size=0.2, random_state=34)\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08477ccf",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "We are given some information on a district and our goal is to predict the median house value in that district. The target variable is expressed in $100k.\n",
    "\n",
    "Normally, we would first do data exploration and cleaning, but since we talked about this in the last chapter, let's jump straight into model code.\n",
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26a7b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestRegressor(max_depth=3, max_features=&#x27;sqrt&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 RandomForestRegressor(max_depth=3, max_features=&#x27;sqrt&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></div></label><div class=\"sk-toggleable__content \"><pre>RandomForestRegressor(max_depth=3, max_features=&#x27;sqrt&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 RandomForestRegressor(max_depth=3, max_features='sqrt'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output-location: slide\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def make_pipeline():\n",
    "  model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    max_features=\"sqrt\"\n",
    "  )\n",
    "\n",
    "  pipeline = Pipeline(\n",
    "    steps=[\n",
    "      (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "      (\"scaler\", StandardScaler()),\n",
    "      (\"model\", model),\n",
    "    ],\n",
    "  )\n",
    "\n",
    "  return pipeline\n",
    "\n",
    "pipeline = make_pipeline()\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1b741",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "We are going to use mean square error (MSE) to evaluate our model. It is computed as follows:\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i^{\\text{true}}-y_i^{\\text{pred}})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd32a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test set: 0.7042428595732597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(f\"MSE on test set: {mean_squared_error(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1a560",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "As you might have noticed, in the `RandomForestRegressor` we specified some parameters:\n",
    "\n",
    "- `n_estimators`: number of trees to fit;\n",
    "- `max_depth`: maximum depth of a fitted tree.\n",
    "\n",
    "There are more, you can see all of them in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "These are called model **hyperparameters**. A hyperparameter is a model parameter that the model does not learn while training. These are left for the model user to specify.\n",
    "\n",
    "So we have a classification:\n",
    "\n",
    "1. Weights: parameters that the model learns while training.\n",
    "2. Hyperparameters: parameters that the model does not learn while training.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "Question is, how do we pick optimal hyperparameters?\n",
    "\n",
    "Usually, it is done through trial and error by trying different combinations of reasonable values and seeing which perform best on the test dataset. This is called **grid search**.\n",
    "\n",
    "## Grid Search\n",
    "\n",
    "To implement a grid search we first need to unhardcode the hyperparameters in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f79662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(n_estimators=100, max_depth=3):\n",
    "  model = RandomForestRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    max_features=\"sqrt\",\n",
    "    n_jobs=-1 # Use max available processors for training and inference\n",
    "  )\n",
    "\n",
    "  pipeline = Pipeline(\n",
    "    steps=[\n",
    "      (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "      (\"scaler\", StandardScaler()),\n",
    "      (\"model\", model),\n",
    "    ],\n",
    "  )\n",
    "\n",
    "  return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd873dd",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "Now implementing a grid search from scratch is not difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "951b5357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination n_estimators=100, max_depth=5 with MSE=0.4985365734911642\n"
     ]
    }
   ],
   "source": [
    "best_n_estimators = -1\n",
    "best_max_depth = -1\n",
    "best_mse = 1000\n",
    "\n",
    "for n_estimators in [50, 100, 200, 500]:\n",
    "  for max_depth in [2, 3, 4, 5]:\n",
    "    pipeline = make_pipeline(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    if mse < best_mse:\n",
    "      best_mse = mse\n",
    "      best_n_estimators = n_estimators\n",
    "      best_max_depth = max_depth\n",
    "\n",
    "print(f\"Best combination n_estimators={best_n_estimators}, max_depth={best_max_depth} with MSE={best_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19785856",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Now that we used our test set to optimize hyperparameters we cannot use it to judge model performance, because we might have \"overfit\" the hyperparameters.\n",
    "\n",
    "This is why usually you should split your data into three parts: train, validation and test:\n",
    "\n",
    "- train: the set that you use to train the model;\n",
    "- validation: the set that you use to tune the model, for example by doing grid search as we did;\n",
    "- test: the set that you use only once at the end of the modelling process to evaluate the model.\n",
    "\n",
    "## Validation\n",
    "\n",
    "Note that its not set in stone which of the datasets are called validation and test. That is some people might switch the definitions around.\n",
    "\n",
    "## Cross-validation\n",
    "\n",
    "If you do not have a second data split for testing you can try to replace it using **cross-validation**.\n",
    "\n",
    "There are several techniques for doing cross-validation. We will describe $K$-fold cross-validation.\n",
    "\n",
    "In $K$-fold cross-validation you split your training data into $k$ parts. Now, in sequence, you take one of the parts to be the validation set and you train the model on the rest of the data. You then compute validation metrics on the validation part and then average these once you are done training $k$ times.\n",
    "\n",
    "Typical values for $k$ are 5 or 10.\n",
    "\n",
    "## Cross-validation\n",
    "\n",
    "Here is how to perform cross validation in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02cf9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation result MSE=0.5037206177056912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "pipeline = make_pipeline(n_estimators=50, max_depth=5)\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "print(f\"Cross validation result MSE={np.mean(-1*scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18fcdfe",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "If your model takes hours to train then cross-validation is not viable. So in practice it is usually best to split you dataset into 3 parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e45726",
   "metadata": {},
   "source": [
    "## Practice problem\n",
    "\n",
    "For practice, try creating a classification model for the [Forest cover types dataset](https://www.kaggle.com/datasets/uciml/forest-cover-type-dataset). It ships with sklearn.\n",
    "\n",
    "If you want to use Random Forest, you will need to use the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) class from sklearn.\n",
    "\n",
    "Here is how to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d368cce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     2596.0    51.0    3.0                             258.0   \n",
       "1     2590.0    56.0    2.0                             212.0   \n",
       "2     2804.0   139.0    9.0                             268.0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             0.0                            510.0   \n",
       "1                            -6.0                            390.0   \n",
       "2                            65.0                           3180.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          221.0           232.0          148.0   \n",
       "1          220.0           235.0          151.0   \n",
       "2          234.0           238.0          135.0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_31  Soil_Type_32  \\\n",
       "0                              6279.0  ...           0.0           0.0   \n",
       "1                              6225.0  ...           0.0           0.0   \n",
       "2                              6121.0  ...           0.0           0.0   \n",
       "\n",
       "   Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  Soil_Type_37  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   Soil_Type_38  Soil_Type_39  target  \n",
       "0           0.0           0.0       5  \n",
       "1           0.0           0.0       5  \n",
       "2           0.0           0.0       2  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "data = fetch_covtype()\n",
    "df = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "df[\"target\"] = data[\"target\"]\n",
    "df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
