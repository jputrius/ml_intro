<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="08_extra_tricks_files/libs/clipboard/clipboard.min.js"></script>
<script src="08_extra_tricks_files/libs/quarto-html/tabby.min.js"></script>
<script src="08_extra_tricks_files/libs/quarto-html/popper.min.js"></script>
<script src="08_extra_tricks_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="08_extra_tricks_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="08_extra_tricks_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="08_extra_tricks_files/libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.26">

  <title>Miscellanea</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="08_extra_tricks_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="08_extra_tricks_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="08_extra_tricks_files/libs/revealjs/dist/theme/quarto-9df06d9b3e1683bd31835b8738a1bbfc.css">
  <link href="08_extra_tricks_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="08_extra_tricks_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="08_extra_tricks_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="08_extra_tricks_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Miscellanea</h1>

<div class="quarto-title-authors">
</div>

</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<p>In this chapter we will go through various topics that did not find their own place in previous chapters.</p>
</section>
<section id="multilabel-classification" class="slide level2">
<h2>Multilabel classification</h2>
<p>There is the following rough classification of classification tasks:</p>
<ol type="1">
<li>Binary - you assign to each sample one of two classes</li>
<li>Multiclass - you assign to each sample one of <span class="math inline">\(N &gt; 2\)</span> classes</li>
<li>Multilabel - you assign to each sample a <strong>subset</strong> of <span class="math inline">\(N\)</span> classes, i.e.&nbsp;one sample can belong to multiple classes</li>
</ol>
</section>
<section id="multilabel-classification-1" class="slide level2">
<h2>Multilabel classification</h2>
<p>We have covered binary and multiclass classification but have not touched multilabel. So let’s do it now.</p>
</section>
<section id="multilabel-classification-2" class="slide level2">
<h2>Multilabel classification</h2>
<p>The way to do multilabel classification with NNs in <code>Pytorch</code> is not much different then the multiclass case.</p>
<ol type="1">
<li>Instead of one encoding your target you encode it using a binary vector of lentgh <span class="math inline">\(N\)</span> (number of classes), where <span class="math inline">\(1\)</span> is in the <span class="math inline">\(n\)</span>-th position if the sample is of class <span class="math inline">\(n\)</span> and <span class="math inline">\(0\)</span> otherwise.</li>
<li>Your model still outputs a <span class="math inline">\(N\)</span> dimensional vector.</li>
</ol>
</section>
<section id="multilabel-classification-3" class="slide level2">
<h2>Multilabel classification</h2>
<ol start="3" type="1">
<li>You use <code>nn.BCEWithLogitsLoss</code> loss function (binary cross-entropy with logit loss). This is sigmoid applied component-wise + cross-entropy.</li>
<li>When inferencing, to get class confidences, you apply sigmoid component-wise to the output.</li>
</ol>
</section>
<section id="multilabel-classification-4" class="slide level2">
<h2>Multilabel classification</h2>
<p>As an example, let’s use this <a href="https://huggingface.co/datasets/google-research-datasets/go_emotions">dataset</a>. It contains reddit comments and the goal is to predict what emotions the comment exhibits. Of course, a tweet might exhibit multiple emotions, so this is a multilabel exercise.</p>
<p>Let’s load the data first.</p>
</section>
<section id="multilabel-classification-5" class="slide level2">
<h2>Multilabel classification</h2>
<div id="78852ec9" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href=""></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href=""></a><span class="im">from</span> spacy.lang.en <span class="im">import</span> English</span>
<span id="cb1-4"><a href=""></a><span class="im">import</span> torch</span>
<span id="cb1-5"><a href=""></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb1-6"><a href=""></a></span>
<span id="cb1-7"><a href=""></a>CLASS_LABELS <span class="op">=</span> [</span>
<span id="cb1-8"><a href=""></a>  <span class="st">'admiration'</span>, <span class="st">'amusement'</span>, <span class="st">'anger'</span>, <span class="st">'annoyance'</span>,</span>
<span id="cb1-9"><a href=""></a>  <span class="st">'approval'</span>, <span class="st">'caring'</span>, <span class="st">'confusion'</span>, <span class="st">'curiosity'</span>,</span>
<span id="cb1-10"><a href=""></a>  <span class="st">'desire'</span>, <span class="st">'disappointment'</span>, <span class="st">'disapproval'</span>, <span class="st">'disgust'</span>,</span>
<span id="cb1-11"><a href=""></a>  <span class="st">'embarrassment'</span>, <span class="st">'excitement'</span>, <span class="st">'fear'</span>, <span class="st">'gratitude'</span>,</span>
<span id="cb1-12"><a href=""></a>  <span class="st">'grief'</span>, <span class="st">'joy'</span>, <span class="st">'love'</span>, <span class="st">'nervousness'</span>,</span>
<span id="cb1-13"><a href=""></a>  <span class="st">'optimism'</span>, <span class="st">'pride'</span>, <span class="st">'realization'</span>, <span class="st">'relief'</span>,</span>
<span id="cb1-14"><a href=""></a>  <span class="st">'remorse'</span>, <span class="st">'sadness'</span>, <span class="st">'surprise'</span>, <span class="st">'neutral'</span></span>
<span id="cb1-15"><a href=""></a>]</span>
<span id="cb1-16"><a href=""></a></span>
<span id="cb1-17"><a href=""></a>TRAIN <span class="op">=</span> pd.read_parquet(<span class="st">"hf://datasets/google-research-datasets/go_emotions/simplified/train-00000-of-00001.parquet"</span>)</span>
<span id="cb1-18"><a href=""></a>TEST <span class="op">=</span> pd.read_parquet(<span class="st">"hf://datasets/google-research-datasets/go_emotions/simplified/test-00000-of-00001.parquet"</span>)</span>
<span id="cb1-19"><a href=""></a></span>
<span id="cb1-20"><a href=""></a>TRAIN</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">labels</th>
<th data-quarto-table-cell-role="th">id</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>My favourite food is anything I didn't have to...</td>
<td>[27]</td>
<td>eebbqej</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>Now if he does off himself, everyone will thin...</td>
<td>[27]</td>
<td>ed00q6i</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>WHY THE FUCK IS BAYLESS ISOING</td>
<td>[2]</td>
<td>eezlygj</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>To make her feel threatened</td>
<td>[14]</td>
<td>ed7ypvh</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>Dirty Southern Wankers</td>
<td>[3]</td>
<td>ed0bdzj</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">...</th>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">43405</th>
<td>Added you mate well I’ve just got the bow and ...</td>
<td>[18]</td>
<td>edsb738</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">43406</th>
<td>Always thought that was funny but is it a refe...</td>
<td>[6]</td>
<td>ee7fdou</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">43407</th>
<td>What are you talking about? Anything bad that ...</td>
<td>[3]</td>
<td>efgbhks</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">43408</th>
<td>More like a baptism, with sexy results!</td>
<td>[13]</td>
<td>ed1naf8</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">43409</th>
<td>Enjoy the ride!</td>
<td>[17]</td>
<td>eecwmbq</td>
</tr>
</tbody>
</table>

<p>43410 rows × 3 columns</p>
</div>
</div>
</div>
</section>
<section id="transformers-for-classification" class="slide level2">
<h2>Transformers for classification</h2>
<p>Transformers can be used for classification.</p>
<p>Let’s train a transformer for this multilabel classification task. There are two modifications we need to make to adapt the transformer we used for text generation to a classification task.</p>
</section>
<section id="transformers-for-classification-1" class="slide level2">
<h2>Transformers for classification</h2>
<p>First, a transformer block produces a sequence of <span class="math inline">\(e\)</span> dimensional vectors, where <span class="math inline">\(e\)</span> is the embedding dimension. What is usually done in classification is that at the end the output of transformer blocks is pooled over the sequence length dimension. Doing this you get a tensor of shape <span class="math inline">\((b, e),\)</span> where <span class="math inline">\(b\)</span> is the batch dimension. You then project this tensor to a tensor of shape <span class="math inline">\((b, c),\)</span> where <span class="math inline">\(c\)</span> is the number of classes, using a matrix.</p>
</section>
<section id="transformers-for-classification-2" class="slide level2">
<h2>Transformers for classification</h2>
<p>Second, we need to change the mask that we use to mask attention weights. If our true sequence length is <span class="math inline">\(l\)</span> (without padding) and the padded sequence length is <span class="math inline">\(n\)</span>, then we can mask the weights in attention layers responsible for generating the last <span class="math inline">\(n-l\)</span> outputs. This mask essentially allows you to work with arbitrary length sequences that are bounded by some fixed length.</p>
<p>This mask improves performance significantly so you should always use it!</p>
</section>
<section id="transformers-for-classification-3" class="slide level2">
<h2>Transformers for classification</h2>
<p>First let’s make a Dataset class for the comments.</p>
<div id="224c639e" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="im">from</span> spacy.lang.en <span class="im">import</span> English</span>
<span id="cb2-2"><a href=""></a><span class="im">import</span> torch</span>
<span id="cb2-3"><a href=""></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb2-4"><a href=""></a></span>
<span id="cb2-5"><a href=""></a><span class="kw">class</span> Dictionary:</span>
<span id="cb2-6"><a href=""></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, min_count<span class="op">=</span><span class="dv">10</span>, init_tokens<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-7"><a href=""></a>    <span class="va">self</span>.nlp <span class="op">=</span> English()</span>
<span id="cb2-8"><a href=""></a>    <span class="va">self</span>.min_count <span class="op">=</span> min_count</span>
<span id="cb2-9"><a href=""></a>    <span class="va">self</span>.init_tokens <span class="op">=</span> init_tokens</span>
<span id="cb2-10"><a href=""></a>    <span class="va">self</span>.i2t, <span class="va">self</span>.t2i, <span class="va">self</span>.no_tokens <span class="op">=</span> <span class="va">self</span>._default_maps()</span>
<span id="cb2-11"><a href=""></a>    <span class="va">self</span>.pad_idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-12"><a href=""></a>    <span class="va">self</span>.unk_idx <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb2-13"><a href=""></a></span>
<span id="cb2-14"><a href=""></a>  <span class="kw">def</span> _default_maps(<span class="va">self</span>):</span>
<span id="cb2-15"><a href=""></a>    <span class="co"># &lt;pad&gt; - token used for padding</span></span>
<span id="cb2-16"><a href=""></a>    <span class="co"># &lt;unk&gt; - unknown, used for tokens not encountered in dictionary building</span></span>
<span id="cb2-17"><a href=""></a>    i2t <span class="op">=</span> [<span class="st">'&lt;pad&gt;'</span>, <span class="st">'&lt;unk&gt;'</span>]</span>
<span id="cb2-18"><a href=""></a>    <span class="cf">if</span> <span class="va">self</span>.init_tokens <span class="op">!=</span> <span class="va">None</span>:</span>
<span id="cb2-19"><a href=""></a>      i2t <span class="op">=</span> [<span class="op">*</span>i2t, <span class="op">*</span><span class="va">self</span>.init_tokens]</span>
<span id="cb2-20"><a href=""></a>    t2i <span class="op">=</span> {token:index <span class="cf">for</span> index, token <span class="kw">in</span> <span class="bu">enumerate</span>(i2t)}</span>
<span id="cb2-21"><a href=""></a>    <span class="cf">return</span> i2t, t2i, <span class="bu">len</span>(i2t)</span>
<span id="cb2-22"><a href=""></a></span>
<span id="cb2-23"><a href=""></a>  <span class="kw">def</span> build(<span class="va">self</span>, corpus):</span>
<span id="cb2-24"><a href=""></a>    tokens <span class="op">=</span> {}</span>
<span id="cb2-25"><a href=""></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> <span class="bu">enumerate</span>(corpus):</span>
<span id="cb2-26"><a href=""></a>      <span class="cf">for</span> token <span class="kw">in</span> <span class="va">self</span>.nlp(row):</span>
<span id="cb2-27"><a href=""></a>        <span class="cf">if</span> token.text.lower() <span class="kw">not</span> <span class="kw">in</span> tokens:</span>
<span id="cb2-28"><a href=""></a>          tokens[token.text.lower()] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb2-29"><a href=""></a>        <span class="cf">else</span>:</span>
<span id="cb2-30"><a href=""></a>          tokens[token.text.lower()] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb2-31"><a href=""></a>    i2t, _, _ <span class="op">=</span> <span class="va">self</span>._default_maps()</span>
<span id="cb2-32"><a href=""></a>    <span class="va">self</span>.i2t <span class="op">=</span> [</span>
<span id="cb2-33"><a href=""></a>      <span class="op">*</span>i2t,</span>
<span id="cb2-34"><a href=""></a>      <span class="op">*</span>[token <span class="cf">for</span> token, count <span class="kw">in</span> tokens.items() <span class="cf">if</span> count <span class="op">&gt;=</span> <span class="va">self</span>.min_count]</span>
<span id="cb2-35"><a href=""></a>    ]</span>
<span id="cb2-36"><a href=""></a>    <span class="va">self</span>.t2i <span class="op">=</span> {token:index <span class="cf">for</span> index, token <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.i2t)}</span>
<span id="cb2-37"><a href=""></a>    <span class="va">self</span>.no_tokens <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.i2t)</span>
<span id="cb2-38"><a href=""></a></span>
<span id="cb2-39"><a href=""></a>  <span class="kw">def</span> string_to_idx(<span class="va">self</span>, string, seq_length<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-40"><a href=""></a>    tokens <span class="op">=</span> [token.text.lower() <span class="cf">for</span> token <span class="kw">in</span> <span class="va">self</span>.nlp(string) <span class="cf">if</span> <span class="kw">not</span> token.is_punct]</span>
<span id="cb2-41"><a href=""></a>    <span class="cf">return</span> <span class="va">self</span>.tokens_to_idx(tokens, seq_length)</span>
<span id="cb2-42"><a href=""></a></span>
<span id="cb2-43"><a href=""></a>  <span class="kw">def</span> tokens_to_idx(<span class="va">self</span>, tokens, seq_length<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-44"><a href=""></a>    idxs <span class="op">=</span> [<span class="va">self</span>.t2i[token] <span class="cf">if</span> token <span class="kw">in</span> <span class="va">self</span>.t2i <span class="cf">else</span> <span class="va">self</span>.unk_idx <span class="cf">for</span> token <span class="kw">in</span> tokens]</span>
<span id="cb2-45"><a href=""></a>    <span class="cf">if</span> seq_length <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb2-46"><a href=""></a>      idxs <span class="op">=</span> idxs <span class="op">+</span> [<span class="va">self</span>.pad_idx] <span class="op">*</span> (seq_length <span class="op">-</span> <span class="bu">len</span>(idxs))</span>
<span id="cb2-47"><a href=""></a>      idxs <span class="op">=</span> idxs[:seq_length]</span>
<span id="cb2-48"><a href=""></a>    <span class="cf">return</span> idxs</span>
<span id="cb2-49"><a href=""></a></span>
<span id="cb2-50"><a href=""></a>  <span class="kw">def</span> idx_to_string(<span class="va">self</span>, indices, ignore_pad<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb2-51"><a href=""></a>    tokens <span class="op">=</span> <span class="va">self</span>.idx_to_tokens(indices, ignore_pad)</span>
<span id="cb2-52"><a href=""></a>    <span class="cf">return</span> tokens.join(<span class="st">' '</span>)</span>
<span id="cb2-53"><a href=""></a></span>
<span id="cb2-54"><a href=""></a>  <span class="kw">def</span> idx_to_tokens(<span class="va">self</span>, indices, ignore_pad<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb2-55"><a href=""></a>    <span class="cf">if</span> ignore_pad:</span>
<span id="cb2-56"><a href=""></a>      <span class="cf">return</span> [<span class="va">self</span>.i2t[idx] <span class="cf">for</span> idx <span class="kw">in</span> indices <span class="cf">if</span> idx <span class="op">!=</span> <span class="va">self</span>.pad_idx]</span>
<span id="cb2-57"><a href=""></a>    <span class="cf">return</span> [<span class="va">self</span>.i2t[idx] <span class="cf">for</span> idx <span class="kw">in</span> indices]</span>
<span id="cb2-58"><a href=""></a></span>
<span id="cb2-59"><a href=""></a><span class="kw">class</span> Comments(Dataset):</span>
<span id="cb2-60"><a href=""></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, seq_length, train<span class="op">=</span><span class="va">False</span>, dictionary<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-61"><a href=""></a>    <span class="va">self</span>.seq_length <span class="op">=</span> seq_length</span>
<span id="cb2-62"><a href=""></a></span>
<span id="cb2-63"><a href=""></a>    <span class="cf">if</span> train:</span>
<span id="cb2-64"><a href=""></a>      <span class="va">self</span>.dataset <span class="op">=</span> TRAIN</span>
<span id="cb2-65"><a href=""></a>    <span class="cf">else</span>:</span>
<span id="cb2-66"><a href=""></a>      <span class="va">self</span>.dataset <span class="op">=</span> TEST</span>
<span id="cb2-67"><a href=""></a></span>
<span id="cb2-68"><a href=""></a>    <span class="cf">if</span> dictionary <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb2-69"><a href=""></a>      <span class="va">self</span>.dictionary <span class="op">=</span> Dictionary()</span>
<span id="cb2-70"><a href=""></a>      <span class="va">self</span>.dictionary.build(<span class="va">self</span>.dataset[<span class="st">"text"</span>])</span>
<span id="cb2-71"><a href=""></a>    <span class="cf">else</span>:</span>
<span id="cb2-72"><a href=""></a>      <span class="va">self</span>.dictionary <span class="op">=</span> dictionary</span>
<span id="cb2-73"><a href=""></a></span>
<span id="cb2-74"><a href=""></a>    <span class="va">self</span>.no_tokens <span class="op">=</span> <span class="va">self</span>.dictionary.no_tokens</span>
<span id="cb2-75"><a href=""></a></span>
<span id="cb2-76"><a href=""></a>  <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb2-77"><a href=""></a>    <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.dataset)</span>
<span id="cb2-78"><a href=""></a></span>
<span id="cb2-79"><a href=""></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb2-80"><a href=""></a>    tokens <span class="op">=</span> <span class="va">self</span>.dictionary.string_to_idx(<span class="va">self</span>.dataset.iloc[idx][<span class="st">"text"</span>], seq_length<span class="op">=</span><span class="va">self</span>.seq_length)</span>
<span id="cb2-81"><a href=""></a>    tokens <span class="op">=</span> torch.LongTensor(tokens)</span>
<span id="cb2-82"><a href=""></a>    mask <span class="op">=</span> <span class="op">~</span>(tokens <span class="op">==</span> <span class="va">self</span>.dictionary.pad_idx)</span>
<span id="cb2-83"><a href=""></a></span>
<span id="cb2-84"><a href=""></a>    target <span class="op">=</span> <span class="va">self</span>.dataset.iloc[idx][<span class="st">"labels"</span>]</span>
<span id="cb2-85"><a href=""></a>    target <span class="op">=</span> torch.zeros(<span class="bu">len</span>(CLASS_LABELS), dtype<span class="op">=</span>torch.<span class="bu">float</span>).scatter_(<span class="dv">0</span>, torch.tensor(target), value<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-86"><a href=""></a>    <span class="cf">return</span> tokens, mask, target</span>
<span id="cb2-87"><a href=""></a></span>
<span id="cb2-88"><a href=""></a>seq_length <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-89"><a href=""></a>batch_size <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb2-90"><a href=""></a></span>
<span id="cb2-91"><a href=""></a>train_data <span class="op">=</span> Comments(</span>
<span id="cb2-92"><a href=""></a>  seq_length<span class="op">=</span>seq_length,</span>
<span id="cb2-93"><a href=""></a>  train<span class="op">=</span><span class="va">True</span></span>
<span id="cb2-94"><a href=""></a>)</span>
<span id="cb2-95"><a href=""></a></span>
<span id="cb2-96"><a href=""></a>test_data <span class="op">=</span> Comments(</span>
<span id="cb2-97"><a href=""></a>  seq_length<span class="op">=</span>seq_length,</span>
<span id="cb2-98"><a href=""></a>  train<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb2-99"><a href=""></a>  dictionary<span class="op">=</span>train_data.dictionary</span>
<span id="cb2-100"><a href=""></a>)</span>
<span id="cb2-101"><a href=""></a></span>
<span id="cb2-102"><a href=""></a>train_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb2-103"><a href=""></a>  train_data,</span>
<span id="cb2-104"><a href=""></a>  batch_size<span class="op">=</span>batch_size,</span>
<span id="cb2-105"><a href=""></a>  shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb2-106"><a href=""></a>)</span>
<span id="cb2-107"><a href=""></a></span>
<span id="cb2-108"><a href=""></a>test_dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb2-109"><a href=""></a>  test_data,</span>
<span id="cb2-110"><a href=""></a>  batch_size<span class="op">=</span>batch_size,</span>
<span id="cb2-111"><a href=""></a>  shuffle<span class="op">=</span><span class="va">False</span></span>
<span id="cb2-112"><a href=""></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="transformers-for-classification-4" class="slide level2">
<h2>Transformers for classification</h2>
<p>Let’s build the model.</p>
<div id="f972d59a" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href=""></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href=""></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb3-3"><a href=""></a></span>
<span id="cb3-4"><a href=""></a><span class="kw">class</span> TransformerClassifier(nn.Module):</span>
<span id="cb3-5"><a href=""></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, no_classes, seq_length, no_tokens, embed_dim, no_heads, depth):</span>
<span id="cb3-6"><a href=""></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-7"><a href=""></a>    <span class="va">self</span>.embed_dim <span class="op">=</span> embed_dim</span>
<span id="cb3-8"><a href=""></a>    <span class="va">self</span>.no_heads <span class="op">=</span> no_heads</span>
<span id="cb3-9"><a href=""></a>    <span class="va">self</span>.depth <span class="op">=</span> depth</span>
<span id="cb3-10"><a href=""></a></span>
<span id="cb3-11"><a href=""></a>    <span class="va">self</span>.token_embedding <span class="op">=</span> nn.Embedding(embedding_dim<span class="op">=</span>embed_dim, num_embeddings<span class="op">=</span>no_tokens)</span>
<span id="cb3-12"><a href=""></a>    <span class="va">self</span>.pos_embedding <span class="op">=</span> nn.Embedding(embedding_dim<span class="op">=</span>embed_dim, num_embeddings<span class="op">=</span>seq_length)</span>
<span id="cb3-13"><a href=""></a></span>
<span id="cb3-14"><a href=""></a>    <span class="va">self</span>.tblocks <span class="op">=</span> nn.ModuleList([</span>
<span id="cb3-15"><a href=""></a>      nn.TransformerEncoderLayer(d_model<span class="op">=</span>embed_dim, nhead<span class="op">=</span>no_heads, dim_feedforward<span class="op">=</span><span class="dv">3072</span>, batch_first<span class="op">=</span><span class="va">True</span>) <span class="co"># Implements GPT style transformer block</span></span>
<span id="cb3-16"><a href=""></a>    ])</span>
<span id="cb3-17"><a href=""></a></span>
<span id="cb3-18"><a href=""></a>    <span class="va">self</span>.toprobs <span class="op">=</span> nn.Linear(embed_dim, no_classes)</span>
<span id="cb3-19"><a href=""></a></span>
<span id="cb3-20"><a href=""></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x, mask):</span>
<span id="cb3-21"><a href=""></a>    tokens <span class="op">=</span> <span class="va">self</span>.token_embedding(x)</span>
<span id="cb3-22"><a href=""></a>    </span>
<span id="cb3-23"><a href=""></a>    b, n, e <span class="op">=</span> tokens.size()</span>
<span id="cb3-24"><a href=""></a>    positions <span class="op">=</span> <span class="va">self</span>.pos_embedding(torch.arange(n, device<span class="op">=</span>tokens.device)).unsqueeze(<span class="dv">0</span>).expand(b, n, e)</span>
<span id="cb3-25"><a href=""></a>    x <span class="op">=</span> tokens <span class="op">+</span> positions</span>
<span id="cb3-26"><a href=""></a></span>
<span id="cb3-27"><a href=""></a>    <span class="cf">for</span> tblock <span class="kw">in</span> <span class="va">self</span>.tblocks:</span>
<span id="cb3-28"><a href=""></a>      x <span class="op">=</span> tblock(x, src_key_padding_mask<span class="op">=</span>mask)</span>
<span id="cb3-29"><a href=""></a></span>
<span id="cb3-30"><a href=""></a>    x, _ <span class="op">=</span> torch.<span class="bu">max</span>(x, dim<span class="op">=</span><span class="dv">1</span>) <span class="co"># Max pool across the seq_length dimension, conveniently this also</span></span>
<span id="cb3-31"><a href=""></a>                               <span class="co"># removes the seq_length dimension from the tensor so we do not need to flatten</span></span>
<span id="cb3-32"><a href=""></a></span>
<span id="cb3-33"><a href=""></a>    <span class="cf">return</span> <span class="va">self</span>.toprobs(x)</span>
<span id="cb3-34"><a href=""></a></span>
<span id="cb3-35"><a href=""></a>  <span class="kw">def</span> predict(<span class="va">self</span>, x, mask):</span>
<span id="cb3-36"><a href=""></a>    <span class="co"># We can abuse the fact that if x &gt; 0 then sigmoid(x) &gt; 0.5</span></span>
<span id="cb3-37"><a href=""></a>    x <span class="op">=</span> <span class="va">self</span>.forward(x, mask)</span>
<span id="cb3-38"><a href=""></a>    <span class="cf">return</span> torch.heaviside(x, torch.tensor(<span class="dv">0</span>, dtype<span class="op">=</span>torch.float32)) <span class="co"># Returns 1 if x &gt; 0 and 0 if x &lt;= 0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="transformers-for-classification-5" class="slide level2">
<h2>Transformers for classification</h2>
<p>Let’s copy over the model training code. Note that we edit it a bit to accomodate the mask and also to account for the multilabel task.</p>
</section>
<section id="transformers-for-classification-6" class="slide level2">
<h2>Transformers for classification</h2>
<div id="0f1e4014" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href=""></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb4-2"><a href=""></a><span class="im">import</span> sys</span>
<span id="cb4-3"><a href=""></a></span>
<span id="cb4-4"><a href=""></a><span class="kw">def</span> train_epoch(dataloader, model, loss_fn, optimizer):</span>
<span id="cb4-5"><a href=""></a>  model.train() <span class="co"># Set model to training mode</span></span>
<span id="cb4-6"><a href=""></a></span>
<span id="cb4-7"><a href=""></a>  total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-8"><a href=""></a>  total_batches <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-9"><a href=""></a></span>
<span id="cb4-10"><a href=""></a>  <span class="cf">with</span> tqdm(dataloader, unit<span class="op">=</span><span class="st">"batch"</span>, <span class="bu">file</span><span class="op">=</span>sys.stdout) <span class="im">as</span> ep_tqdm:</span>
<span id="cb4-11"><a href=""></a>    ep_tqdm.set_description(<span class="st">"Train"</span>)</span>
<span id="cb4-12"><a href=""></a>    <span class="cf">for</span> X, mask, y <span class="kw">in</span> ep_tqdm:</span>
<span id="cb4-13"><a href=""></a>      X, mask, y <span class="op">=</span> X.to(device), mask.to(device), y.to(device)</span>
<span id="cb4-14"><a href=""></a></span>
<span id="cb4-15"><a href=""></a>      <span class="co"># Forward pass</span></span>
<span id="cb4-16"><a href=""></a>      pred <span class="op">=</span> model(X, mask)</span>
<span id="cb4-17"><a href=""></a>      loss <span class="op">=</span> loss_fn(pred, y)</span>
<span id="cb4-18"><a href=""></a>        </span>
<span id="cb4-19"><a href=""></a>      <span class="co"># Backward pass</span></span>
<span id="cb4-20"><a href=""></a>      loss.backward()</span>
<span id="cb4-21"><a href=""></a>      optimizer.step()</span>
<span id="cb4-22"><a href=""></a></span>
<span id="cb4-23"><a href=""></a>      <span class="co"># Reset the computed gradients back to zero</span></span>
<span id="cb4-24"><a href=""></a>      optimizer.zero_grad()</span>
<span id="cb4-25"><a href=""></a></span>
<span id="cb4-26"><a href=""></a>      <span class="co"># Output stats</span></span>
<span id="cb4-27"><a href=""></a>      total_loss <span class="op">+=</span> loss</span>
<span id="cb4-28"><a href=""></a>      total_batches <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-29"><a href=""></a>      ep_tqdm.set_postfix(average_batch_loss<span class="op">=</span>(total_loss<span class="op">/</span>total_batches).item())</span>
<span id="cb4-30"><a href=""></a></span>
<span id="cb4-31"><a href=""></a><span class="kw">def</span> eval_epoch(dataloader, model, loss_fn):</span>
<span id="cb4-32"><a href=""></a>  model.<span class="bu">eval</span>() <span class="co"># Set model to inference mode</span></span>
<span id="cb4-33"><a href=""></a>  </span>
<span id="cb4-34"><a href=""></a>  total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-35"><a href=""></a>  total_batches <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-36"><a href=""></a></span>
<span id="cb4-37"><a href=""></a>  <span class="cf">with</span> torch.no_grad(): <span class="co"># Do not compute gradients</span></span>
<span id="cb4-38"><a href=""></a>    <span class="cf">with</span> tqdm(dataloader, unit<span class="op">=</span><span class="st">"batch"</span>, <span class="bu">file</span><span class="op">=</span>sys.stdout) <span class="im">as</span> ep_tqdm:</span>
<span id="cb4-39"><a href=""></a>      ep_tqdm.set_description(<span class="st">"Val"</span>)</span>
<span id="cb4-40"><a href=""></a>      <span class="cf">for</span> X, mask, y <span class="kw">in</span> ep_tqdm:</span>
<span id="cb4-41"><a href=""></a>        X, mask, y <span class="op">=</span> X.to(device), mask.to(device), y.to(device)</span>
<span id="cb4-42"><a href=""></a>        pred <span class="op">=</span> model(X, mask)</span>
<span id="cb4-43"><a href=""></a></span>
<span id="cb4-44"><a href=""></a>        total_loss <span class="op">+=</span> loss_fn(pred, y)</span>
<span id="cb4-45"><a href=""></a>        total_batches <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-46"><a href=""></a></span>
<span id="cb4-47"><a href=""></a>        ep_tqdm.set_postfix(average_batch_loss<span class="op">=</span>(total_loss<span class="op">/</span>total_batches).item())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="transformers-for-classification-7" class="slide level2">
<h2>Transformers for classification</h2>
<p>Now we can train the model! Remember to use the appropriate loss function for multilabel tasks.</p>
<div id="6d39d57d" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href=""></a><span class="co"># Hyperparameters</span></span>
<span id="cb5-2"><a href=""></a>learning_rate <span class="op">=</span> <span class="fl">0.0001</span></span>
<span id="cb5-3"><a href=""></a>epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb5-4"><a href=""></a></span>
<span id="cb5-5"><a href=""></a>device <span class="op">=</span> torch.accelerator.current_accelerator().<span class="bu">type</span> <span class="cf">if</span> torch.accelerator.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb5-6"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device"</span>)</span>
<span id="cb5-7"><a href=""></a></span>
<span id="cb5-8"><a href=""></a>model <span class="op">=</span> TransformerClassifier(<span class="bu">len</span>(CLASS_LABELS), seq_length, train_data.no_tokens, <span class="dv">1024</span>, <span class="dv">16</span>, <span class="dv">6</span>).to(device)</span>
<span id="cb5-9"><a href=""></a></span>
<span id="cb5-10"><a href=""></a>loss_fn <span class="op">=</span> nn.BCEWithLogitsLoss().to(device)</span>
<span id="cb5-11"><a href=""></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb5-12"><a href=""></a></span>
<span id="cb5-13"><a href=""></a><span class="co"># Organize the training loop</span></span>
<span id="cb5-14"><a href=""></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb5-15"><a href=""></a>  <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-------------------------------"</span>)</span>
<span id="cb5-16"><a href=""></a>  train_epoch(train_dataloader, model, loss_fn, optimizer)</span>
<span id="cb5-17"><a href=""></a>  eval_epoch(test_dataloader, model, loss_fn)</span>
<span id="cb5-18"><a href=""></a></span>
<span id="cb5-19"><a href=""></a><span class="bu">print</span>(<span class="st">"Done!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>

</section>
<section id="transformers-for-classification-7-output" class="slide level2 output-location-slide"><h2>Transformers for classification</h2><div class="cell output-location-slide" data-execution_count="5">
<div class="cell-output cell-output-stdout">
<pre><code>Using cuda device
Epoch 1
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.56batch/s, average_batch_loss=0.148]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 32.53batch/s, average_batch_loss=0.125]
Epoch 2
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.81batch/s, average_batch_loss=0.116]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 34.09batch/s, average_batch_loss=0.11] 
Epoch 3
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.78batch/s, average_batch_loss=0.106]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.78batch/s, average_batch_loss=0.104]
Epoch 4
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.93batch/s, average_batch_loss=0.1]  
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.76batch/s, average_batch_loss=0.102]
Epoch 5
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.75batch/s, average_batch_loss=0.0961]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 34.14batch/s, average_batch_loss=0.101]
Epoch 6
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.68batch/s, average_batch_loss=0.0927]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.92batch/s, average_batch_loss=0.0993]
Epoch 7
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.81batch/s, average_batch_loss=0.0894]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.81batch/s, average_batch_loss=0.0983]
Epoch 8
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.72batch/s, average_batch_loss=0.0863]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.93batch/s, average_batch_loss=0.0997]
Epoch 9
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.72batch/s, average_batch_loss=0.083] 
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.56batch/s, average_batch_loss=0.0977]
Epoch 10
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.82batch/s, average_batch_loss=0.0798]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.99batch/s, average_batch_loss=0.0993]
Epoch 11
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.81batch/s, average_batch_loss=0.0765]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.99batch/s, average_batch_loss=0.0983]
Epoch 12
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.77batch/s, average_batch_loss=0.073] 
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.99batch/s, average_batch_loss=0.1]   
Epoch 13
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.79batch/s, average_batch_loss=0.0696]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.87batch/s, average_batch_loss=0.1]   
Epoch 14
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.62batch/s, average_batch_loss=0.0662]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.84batch/s, average_batch_loss=0.104]
Epoch 15
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.42batch/s, average_batch_loss=0.0628]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.45batch/s, average_batch_loss=0.104]
Epoch 16
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.57batch/s, average_batch_loss=0.0592]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 34.36batch/s, average_batch_loss=0.107]
Epoch 17
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.33batch/s, average_batch_loss=0.0558]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 32.88batch/s, average_batch_loss=0.108]
Epoch 18
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.41batch/s, average_batch_loss=0.0525]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.70batch/s, average_batch_loss=0.11] 
Epoch 19
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.55batch/s, average_batch_loss=0.0493]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.58batch/s, average_batch_loss=0.111]
Epoch 20
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.58batch/s, average_batch_loss=0.0458]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.31batch/s, average_batch_loss=0.112]
Done!</code></pre>
</div>
</div></section><section id="transformers-for-classification-8" class="slide level2">
<h2>Transformers for classification</h2>
<p>Let’s compute precision and recall.</p>
<div id="5ac0fcef" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href=""></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb7-2"><a href=""></a></span>
<span id="cb7-3"><a href=""></a><span class="kw">def</span> compute_classification_report(model, dataloader):</span>
<span id="cb7-4"><a href=""></a>  <span class="cf">with</span> torch.no_grad():</span>
<span id="cb7-5"><a href=""></a>    y_pred <span class="op">=</span> []</span>
<span id="cb7-6"><a href=""></a>    y_true <span class="op">=</span> []</span>
<span id="cb7-7"><a href=""></a>    <span class="cf">for</span> X, mask, y <span class="kw">in</span> dataloader:</span>
<span id="cb7-8"><a href=""></a>      X, mask, y <span class="op">=</span> X.to(device), mask.to(device), y.to(device)</span>
<span id="cb7-9"><a href=""></a>      y_pred <span class="op">=</span> [<span class="op">*</span>y_pred, <span class="op">*</span>model.predict(X, mask).cpu()]</span>
<span id="cb7-10"><a href=""></a>      y_true <span class="op">=</span> [<span class="op">*</span>y_true, <span class="op">*</span>y.cpu()]</span>
<span id="cb7-11"><a href=""></a>    <span class="bu">print</span>(classification_report(y_true, y_pred, target_names<span class="op">=</span>CLASS_LABELS, zero_division<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb7-12"><a href=""></a></span>
<span id="cb7-13"><a href=""></a>compute_classification_report(model, test_dataloader)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>

</section>
<section id="transformers-for-classification-8-output" class="slide level2 output-location-slide"><h2>Transformers for classification</h2><div class="cell output-location-slide">
<div class="cell-output cell-output-stdout">
<pre><code>                precision    recall  f1-score   support

    admiration       0.68      0.51      0.58       504
     amusement       0.77      0.75      0.76       264
         anger       0.52      0.27      0.36       198
     annoyance       0.43      0.15      0.22       320
      approval       0.40      0.25      0.31       351
        caring       0.35      0.17      0.23       135
     confusion       0.35      0.24      0.29       153
     curiosity       0.42      0.25      0.31       284
        desire       0.54      0.25      0.34        83
disappointment       0.36      0.13      0.19       151
   disapproval       0.40      0.08      0.13       267
       disgust       0.59      0.38      0.46       123
 embarrassment       0.44      0.19      0.26        37
    excitement       0.45      0.27      0.34       103
          fear       0.70      0.49      0.58        78
     gratitude       0.94      0.91      0.93       352
         grief       0.00      0.00      0.00         6
           joy       0.64      0.43      0.51       161
          love       0.77      0.72      0.74       238
   nervousness       0.33      0.13      0.19        23
      optimism       0.65      0.46      0.54       186
         pride       0.80      0.25      0.38        16
   realization       0.44      0.11      0.18       145
        relief       0.00      0.00      0.00        11
       remorse       0.61      0.73      0.67        56
       sadness       0.60      0.42      0.49       156
      surprise       0.52      0.33      0.40       141
       neutral       0.56      0.62      0.59      1787

     micro avg       0.59      0.46      0.52      6329
     macro avg       0.51      0.34      0.39      6329
  weighted avg       0.56      0.46      0.49      6329
   samples avg       0.48      0.48      0.47      6329
</code></pre>
</div>
</div></section><section id="early-stopping" class="slide level2">
<h2>Early stopping</h2>
<p>If you check the training statistics you will see that the model overfit.</p>
<p>It is a good idea to stop training when your model starts to overfit, i.e.&nbsp;the performance degrades on the validation set. This is called early stopping.</p>
<p>To implement early stopping in <code>pytorch</code> we first need to make our model evaluation function output the statistics.</p>
</section>
<section id="early-stopping-1" class="slide level2">
<h2>Early stopping</h2>
<div id="25668b40" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href=""></a><span class="kw">def</span> eval_epoch(dataloader, model, loss_fn):</span>
<span id="cb9-2"><a href=""></a>  model.<span class="bu">eval</span>() <span class="co"># Set model to inference mode</span></span>
<span id="cb9-3"><a href=""></a>  </span>
<span id="cb9-4"><a href=""></a>  total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-5"><a href=""></a>  total_batches <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-6"><a href=""></a></span>
<span id="cb9-7"><a href=""></a>  <span class="cf">with</span> torch.no_grad(): <span class="co"># Do not compute gradients</span></span>
<span id="cb9-8"><a href=""></a>    <span class="cf">with</span> tqdm(dataloader, unit<span class="op">=</span><span class="st">"batch"</span>, <span class="bu">file</span><span class="op">=</span>sys.stdout) <span class="im">as</span> ep_tqdm:</span>
<span id="cb9-9"><a href=""></a>      ep_tqdm.set_description(<span class="st">"Val"</span>)</span>
<span id="cb9-10"><a href=""></a>      <span class="cf">for</span> X, mask, y <span class="kw">in</span> ep_tqdm:</span>
<span id="cb9-11"><a href=""></a>        X, mask, y <span class="op">=</span> X.to(device), mask.to(device), y.to(device)</span>
<span id="cb9-12"><a href=""></a>        pred <span class="op">=</span> model(X, mask)</span>
<span id="cb9-13"><a href=""></a></span>
<span id="cb9-14"><a href=""></a>        total_loss <span class="op">+=</span> loss_fn(pred, y)</span>
<span id="cb9-15"><a href=""></a>        total_batches <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb9-16"><a href=""></a></span>
<span id="cb9-17"><a href=""></a>        ep_tqdm.set_postfix(average_batch_loss<span class="op">=</span>(total_loss<span class="op">/</span>total_batches).item())</span>
<span id="cb9-18"><a href=""></a>  </span>
<span id="cb9-19"><a href=""></a>  <span class="cf">return</span> (total_loss<span class="op">/</span>total_batches).item()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="early-stopping-2" class="slide level2">
<h2>Early stopping</h2>
<p>To decide whether we should stop early we are going to need to keep some extra state. So the cleanest solution would be to have an extra object that monitors training and decides whether we should stop.</p>
</section>
<section id="early-stopping-3" class="slide level2">
<h2>Early stopping</h2>
<div id="cd0629a9" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href=""></a><span class="kw">class</span> EarlyStopper:</span>
<span id="cb10-2"><a href=""></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, patience<span class="op">=</span><span class="dv">1</span>, threshold<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb10-3"><a href=""></a>    <span class="va">self</span>.patience <span class="op">=</span> patience</span>
<span id="cb10-4"><a href=""></a>    <span class="va">self</span>.annoyance <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb10-5"><a href=""></a></span>
<span id="cb10-6"><a href=""></a>    <span class="va">self</span>.threshold <span class="op">=</span> threshold</span>
<span id="cb10-7"><a href=""></a>    <span class="va">self</span>.best_epoch <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb10-8"><a href=""></a>    <span class="va">self</span>.min_loss <span class="op">=</span> <span class="dv">99999999999</span></span>
<span id="cb10-9"><a href=""></a></span>
<span id="cb10-10"><a href=""></a>  <span class="kw">def</span> should_early_stop(<span class="va">self</span>, loss, epoch):</span>
<span id="cb10-11"><a href=""></a>    <span class="cf">if</span> loss <span class="op">&lt;</span> <span class="va">self</span>.min_loss:</span>
<span id="cb10-12"><a href=""></a>      <span class="va">self</span>.min_loss <span class="op">=</span> loss</span>
<span id="cb10-13"><a href=""></a>      <span class="va">self</span>.annoyance <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb10-14"><a href=""></a>      <span class="va">self</span>.best_epoch <span class="op">=</span> epoch</span>
<span id="cb10-15"><a href=""></a>    <span class="cf">elif</span> loss <span class="op">&gt;</span> (<span class="va">self</span>.min_loss <span class="op">+</span> <span class="va">self</span>.threshold):</span>
<span id="cb10-16"><a href=""></a>      <span class="va">self</span>.annoyance <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb10-17"><a href=""></a>      <span class="cf">if</span> <span class="va">self</span>.annoyance <span class="op">&gt;=</span> <span class="va">self</span>.patience:</span>
<span id="cb10-18"><a href=""></a>        <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb10-19"><a href=""></a>    <span class="cf">return</span> <span class="va">False</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="early-stopping-4" class="slide level2">
<h2>Early stopping</h2>
<p>Next we update our training routine to monitor overfitting. We also save our model every epoch so that we could go back to the best iteration.</p>
<p>Saving your model every training epoch is called model checkpointing and its a good thing to do in general. For example, if the machine you are training on decides to crash you will not loose all your progress if you saved some checkpoints.</p>
</section>
<section id="early-stopping-5" class="slide level2">
<h2>Early stopping</h2>
<div id="a4654d38" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href=""></a><span class="im">import</span> os</span>
<span id="cb11-2"><a href=""></a></span>
<span id="cb11-3"><a href=""></a><span class="co"># Create a directory for checkpoints</span></span>
<span id="cb11-4"><a href=""></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"./checkpoints"</span>):</span>
<span id="cb11-5"><a href=""></a>  os.makedirs(<span class="st">"./checkpoints"</span>)</span>
<span id="cb11-6"><a href=""></a></span>
<span id="cb11-7"><a href=""></a><span class="co"># Hyperparameters</span></span>
<span id="cb11-8"><a href=""></a>learning_rate <span class="op">=</span> <span class="fl">0.0001</span></span>
<span id="cb11-9"><a href=""></a>epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb11-10"><a href=""></a></span>
<span id="cb11-11"><a href=""></a>device <span class="op">=</span> torch.accelerator.current_accelerator().<span class="bu">type</span> <span class="cf">if</span> torch.accelerator.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb11-12"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device"</span>)</span>
<span id="cb11-13"><a href=""></a></span>
<span id="cb11-14"><a href=""></a>model <span class="op">=</span> TransformerClassifier(<span class="bu">len</span>(CLASS_LABELS), seq_length, train_data.no_tokens, <span class="dv">768</span>, <span class="dv">12</span>, <span class="dv">6</span>).to(device)</span>
<span id="cb11-15"><a href=""></a></span>
<span id="cb11-16"><a href=""></a>loss_fn <span class="op">=</span> nn.BCEWithLogitsLoss().to(device)</span>
<span id="cb11-17"><a href=""></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb11-18"><a href=""></a>stopper <span class="op">=</span> EarlyStopper(patience<span class="op">=</span><span class="dv">2</span>, threshold<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb11-19"><a href=""></a></span>
<span id="cb11-20"><a href=""></a><span class="co"># Organize the training loop</span></span>
<span id="cb11-21"><a href=""></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb11-22"><a href=""></a>  <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-------------------------------"</span>)</span>
<span id="cb11-23"><a href=""></a>  train_epoch(train_dataloader, model, loss_fn, optimizer)</span>
<span id="cb11-24"><a href=""></a>  loss <span class="op">=</span> eval_epoch(test_dataloader, model, loss_fn)</span>
<span id="cb11-25"><a href=""></a>  torch.save(model, <span class="ss">f"./checkpoints/model_epoch_</span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">.pth"</span>)</span>
<span id="cb11-26"><a href=""></a></span>
<span id="cb11-27"><a href=""></a>  <span class="cf">if</span> stopper.should_early_stop(loss, t<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb11-28"><a href=""></a>    <span class="bu">print</span>(<span class="st">"Stopping early"</span>)</span>
<span id="cb11-29"><a href=""></a>    <span class="cf">break</span></span>
<span id="cb11-30"><a href=""></a></span>
<span id="cb11-31"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Loading checkpoint for best epoch </span><span class="sc">{</span>stopper<span class="sc">.</span>best_epoch<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-32"><a href=""></a>model <span class="op">=</span> torch.load(<span class="ss">f"./checkpoints/model_epoch_</span><span class="sc">{</span>stopper<span class="sc">.</span>best_epoch<span class="sc">}</span><span class="ss">.pth"</span>, weights_only<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-33"><a href=""></a><span class="bu">print</span>(<span class="st">"Done!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>

</section>
<section id="early-stopping-5-output" class="slide level2 output-location-slide"><h2>Early stopping</h2><div class="cell output-location-slide" data-execution_count="9">
<div class="cell-output cell-output-stdout">
<pre><code>Using cuda device
Epoch 1
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.21batch/s, average_batch_loss=0.154]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 41.25batch/s, average_batch_loss=0.134]
Epoch 2
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.35batch/s, average_batch_loss=0.123]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 41.09batch/s, average_batch_loss=0.115]
Epoch 3
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.54batch/s, average_batch_loss=0.11] 
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 42.58batch/s, average_batch_loss=0.107]
Epoch 4
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.40batch/s, average_batch_loss=0.104]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 40.71batch/s, average_batch_loss=0.103]
Epoch 5
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.56batch/s, average_batch_loss=0.0993]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 40.74batch/s, average_batch_loss=0.101] 
Epoch 6
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.87batch/s, average_batch_loss=0.0958]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 42.06batch/s, average_batch_loss=0.0992]
Epoch 7
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.88batch/s, average_batch_loss=0.0926]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 42.31batch/s, average_batch_loss=0.0984]
Epoch 8
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.37batch/s, average_batch_loss=0.0898]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 41.35batch/s, average_batch_loss=0.0977]
Epoch 9
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.13batch/s, average_batch_loss=0.0869]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 40.05batch/s, average_batch_loss=0.0974]
Epoch 10
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 25.15batch/s, average_batch_loss=0.0839]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 40.52batch/s, average_batch_loss=0.0978]
Epoch 11
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 24.74batch/s, average_batch_loss=0.0813]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 40.25batch/s, average_batch_loss=0.0981]
Epoch 12
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 24.97batch/s, average_batch_loss=0.0784]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 39.53batch/s, average_batch_loss=0.0986]
Epoch 13
-------------------------------
Train: 100%|██████████| 340/340 [00:13&lt;00:00, 24.91batch/s, average_batch_loss=0.0757]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 37.64batch/s, average_batch_loss=0.0998]
Stopping early
Loading checkpoint for best epoch 9
Done!</code></pre>
</div>
</div></section><section id="early-stopping-6" class="slide level2">
<h2>Early stopping</h2>
<p>Let’s compute precision and recall again.</p>
<div id="5a44a016" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href=""></a>compute_classification_report(model, test_dataloader)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>                precision    recall  f1-score   support

    admiration       0.64      0.57      0.61       504
     amusement       0.75      0.82      0.78       264
         anger       0.62      0.19      0.29       198
     annoyance       0.44      0.15      0.22       320
      approval       0.57      0.19      0.29       351
        caring       0.41      0.13      0.20       135
     confusion       0.45      0.07      0.11       153
     curiosity       0.48      0.18      0.26       284
        desire       0.58      0.23      0.33        83
disappointment       0.50      0.01      0.01       151
   disapproval       0.37      0.06      0.10       267
       disgust       0.65      0.27      0.38       123
 embarrassment       0.00      0.00      0.00        37
    excitement       0.54      0.26      0.35       103
          fear       0.76      0.37      0.50        78
     gratitude       0.93      0.90      0.91       352
         grief       0.00      0.00      0.00         6
           joy       0.66      0.48      0.55       161
          love       0.77      0.76      0.76       238
   nervousness       0.00      0.00      0.00        23
      optimism       0.71      0.46      0.56       186
         pride       0.00      0.00      0.00        16
   realization       0.75      0.04      0.08       145
        relief       0.00      0.00      0.00        11
       remorse       0.61      0.61      0.61        56
       sadness       0.72      0.28      0.41       156
      surprise       0.59      0.29      0.39       141
       neutral       0.64      0.55      0.59      1787

     micro avg       0.66      0.41      0.51      6329
     macro avg       0.50      0.28      0.33      6329
  weighted avg       0.62      0.41      0.47      6329
   samples avg       0.45      0.43      0.44      6329
</code></pre>
</div>
</div>
</section>
<section id="balancing-class-weights" class="slide level2">
<h2>Balancing class weights</h2>
<p>Now let’s return to a multiclass classification problem.</p>
<p>Very often the distribution of the labels in your training dataset will not match the distribution that you will encouter in the “wild” (i.e.&nbsp;production). This happens due to a variety of factors. For example, it might be that indentifying one specific label is much easier then the rest. So, over time your training set will gather unproportionally more examples of that label.</p>
</section>
<section id="balancing-class-weights-1" class="slide level2">
<h2>Balancing class weights</h2>
<p>The problem is that the model will learn this incorrect distribution. For example, if 90% of your training set is made up of one label then the model will be very trigger happy when assigning that label.</p>
<p>In practice, if the distribution of your training set is skewed, it is better to rebalance the distribution such that it is uniform. That is, make the model learn that each label is as likely as the next one.</p>
</section>
<section id="balancing-class-weights-2" class="slide level2">
<h2>Balancing class weights</h2>
<p>This can be done by balancing the class weights. That is, you assign a bigger weight to a sample if its label is more rare in the training dataset.</p>
<p>The formula you can use is <span class="math display">\[
  \text{weight}_i = \frac{\text{total no of samples}}{\text{no of classes}\times\text{no of samples of class i}}.
\]</span></p>
</section>
<section id="balancing-class-weights-3" class="slide level2">
<h2>Balancing class weights</h2>
<p>Note that doing this will probably reduce the performance of the model on your validation and test datasets (if these have the same wrong distribution), however the point is that it will improve performance in production.</p>
</section>
<section id="balancing-class-weights-4" class="slide level2">
<h2>Balancing class weights</h2>
<p>In <code>sklearn</code>, models have a <code>class_weight</code> parameter, which you can set to <code>'balanced'</code> to apply the above formula.</p>
<p>Here is one way to do this in <code>pytorch</code>:</p>
</section>
<section id="balancing-class-weights-5" class="slide level2">
<h2>Balancing class weights</h2>
<pre><code>def compute_class_weights(dataloader):
  classes = []
  for _, _, y in dataloader:
    classes = [*classes, *y.argmax(dim=1)]
  
  no_classes = len(np.unique(classes))
  no_total = len(classes)
  no_in_class = np.unique_counts(classes).counts
  return torch.tensor(no_total/(no_classes*no_in_class))

weights = compute_class_weights(some_dataloader)
loss_fn = nn.CrossEntropyLoss(weight=class_weights).to(device)</code></pre>
</section>
<section id="learning-rate-scheduling-and-warmup" class="slide level2">
<h2>Learning rate scheduling and warmup</h2>
<p>Neural networks with many layers might have trouble converging when you start training on fresh random weights. I.e. if you had weights that were approximately correct the training would converge, however when you start with random weights training diverges.</p>
<p>There is a standard technique for mitigating this called warmup. The idea is that you start training with a very low learning rate for the first few epochs and then crank the learning rate back up to a normal level.</p>
<p>Our model is not really deep enough to benefit from warmup, but we can still checkout how to implement it in <code>pytorch</code>.</p>
</section>
<section id="learning-rate-scheduling-and-warmup-1" class="slide level2">
<h2>Learning rate scheduling and warmup</h2>
<p>Also, if you are using SGD to train it might be a good idea to periodically reduce the learning rate as you are training. This is not that necessary when using Adam or its variants.</p>
<p>In general, if you are tweaking the learning rate during training this is called learning rate scheduling.</p>
</section>
<section id="learning-rate-scheduling-and-warmup-2" class="slide level2">
<h2>Learning rate scheduling and warmup</h2>
<div id="72ad92be" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href=""></a><span class="im">import</span> os</span>
<span id="cb16-2"><a href=""></a></span>
<span id="cb16-3"><a href=""></a><span class="co"># Create a directory for checkpoints</span></span>
<span id="cb16-4"><a href=""></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"./checkpoints"</span>):</span>
<span id="cb16-5"><a href=""></a>  os.makedirs(<span class="st">"./checkpoints"</span>)</span>
<span id="cb16-6"><a href=""></a></span>
<span id="cb16-7"><a href=""></a><span class="co"># Hyperparameters</span></span>
<span id="cb16-8"><a href=""></a>learning_rate <span class="op">=</span> <span class="fl">0.0001</span></span>
<span id="cb16-9"><a href=""></a>epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb16-10"><a href=""></a></span>
<span id="cb16-11"><a href=""></a>device <span class="op">=</span> torch.accelerator.current_accelerator().<span class="bu">type</span> <span class="cf">if</span> torch.accelerator.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb16-12"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device"</span>)</span>
<span id="cb16-13"><a href=""></a></span>
<span id="cb16-14"><a href=""></a>model <span class="op">=</span> TransformerClassifier(<span class="bu">len</span>(CLASS_LABELS), seq_length, train_data.no_tokens, <span class="dv">1024</span>, <span class="dv">16</span>, <span class="dv">6</span>).to(device)</span>
<span id="cb16-15"><a href=""></a></span>
<span id="cb16-16"><a href=""></a>loss_fn <span class="op">=</span> nn.BCEWithLogitsLoss().to(device)</span>
<span id="cb16-17"><a href=""></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb16-18"><a href=""></a>scheduler <span class="op">=</span> torch.optim.lr_scheduler.ConstantLR(optimizer, factor<span class="op">=</span><span class="fl">0.1</span>, total_iters<span class="op">=</span><span class="dv">5</span>) <span class="co"># Multiplies the LR by factor for total_iters iterations, there are other schedulers available in Pytorch</span></span>
<span id="cb16-19"><a href=""></a>stopper <span class="op">=</span> EarlyStopper(patience<span class="op">=</span><span class="dv">2</span>, threshold<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb16-20"><a href=""></a></span>
<span id="cb16-21"><a href=""></a><span class="co"># Organize the training loop</span></span>
<span id="cb16-22"><a href=""></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb16-23"><a href=""></a>  <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-------------------------------"</span>)</span>
<span id="cb16-24"><a href=""></a>  train_epoch(train_dataloader, model, loss_fn, optimizer)</span>
<span id="cb16-25"><a href=""></a>  loss <span class="op">=</span> eval_epoch(test_dataloader, model, loss_fn)</span>
<span id="cb16-26"><a href=""></a>  torch.save(model, <span class="ss">f"./checkpoints/model_epoch_</span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">.pth"</span>)</span>
<span id="cb16-27"><a href=""></a>  scheduler.step()</span>
<span id="cb16-28"><a href=""></a></span>
<span id="cb16-29"><a href=""></a>  <span class="cf">if</span> stopper.should_early_stop(loss, t<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb16-30"><a href=""></a>    <span class="bu">print</span>(<span class="st">"Stopping early"</span>)</span>
<span id="cb16-31"><a href=""></a>    <span class="cf">break</span></span>
<span id="cb16-32"><a href=""></a></span>
<span id="cb16-33"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Loading checkpoint for best epoch </span><span class="sc">{</span>stopper<span class="sc">.</span>best_epoch<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-34"><a href=""></a>model <span class="op">=</span> torch.load(<span class="ss">f"./checkpoints/model_epoch_</span><span class="sc">{</span>stopper<span class="sc">.</span>best_epoch<span class="sc">}</span><span class="ss">.pth"</span>, weights_only<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-35"><a href=""></a><span class="bu">print</span>(<span class="st">"Done!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>

</section>
<section id="learning-rate-scheduling-and-warmup-2-output" class="slide level2 output-location-slide"><h2>Learning rate scheduling and warmup</h2><div class="cell output-location-slide" data-execution_count="12">
<div class="cell-output cell-output-stdout">
<pre><code>Using cuda device
Epoch 1
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.71batch/s, average_batch_loss=0.178]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.97batch/s, average_batch_loss=0.147]
Epoch 2
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.48batch/s, average_batch_loss=0.148]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.55batch/s, average_batch_loss=0.145]
Epoch 3
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.54batch/s, average_batch_loss=0.146]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.15batch/s, average_batch_loss=0.143]
Epoch 4
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.25batch/s, average_batch_loss=0.142]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.09batch/s, average_batch_loss=0.138]
Epoch 5
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.37batch/s, average_batch_loss=0.137]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.04batch/s, average_batch_loss=0.132]
Epoch 6
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.50batch/s, average_batch_loss=0.121]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.29batch/s, average_batch_loss=0.112]
Epoch 7
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.45batch/s, average_batch_loss=0.108]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.50batch/s, average_batch_loss=0.109]
Epoch 8
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.57batch/s, average_batch_loss=0.101]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.54batch/s, average_batch_loss=0.101]
Epoch 9
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.51batch/s, average_batch_loss=0.0964]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.55batch/s, average_batch_loss=0.0996]
Epoch 10
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.52batch/s, average_batch_loss=0.0927]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.46batch/s, average_batch_loss=0.0984]
Epoch 11
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.55batch/s, average_batch_loss=0.0895]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.62batch/s, average_batch_loss=0.0971]
Epoch 12
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.57batch/s, average_batch_loss=0.0863]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.39batch/s, average_batch_loss=0.0974]
Epoch 13
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.70batch/s, average_batch_loss=0.083] 
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.80batch/s, average_batch_loss=0.0993]
Epoch 14
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.56batch/s, average_batch_loss=0.0803]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.11batch/s, average_batch_loss=0.0985]
Epoch 15
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.32batch/s, average_batch_loss=0.0771]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.24batch/s, average_batch_loss=0.0994]
Epoch 16
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.35batch/s, average_batch_loss=0.0738]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.06batch/s, average_batch_loss=0.101]
Epoch 17
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.25batch/s, average_batch_loss=0.0703]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 32.93batch/s, average_batch_loss=0.101]
Epoch 18
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.26batch/s, average_batch_loss=0.0672]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 33.08batch/s, average_batch_loss=0.102]
Epoch 19
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.23batch/s, average_batch_loss=0.0638]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 32.86batch/s, average_batch_loss=0.103]
Epoch 20
-------------------------------
Train: 100%|██████████| 340/340 [00:17&lt;00:00, 19.32batch/s, average_batch_loss=0.0605]
Val: 100%|██████████| 43/43 [00:01&lt;00:00, 32.71batch/s, average_batch_loss=0.105]
Loading checkpoint for best epoch 11
Done!</code></pre>
</div>
</div></section><section id="dropout" class="slide level2">
<h2>Dropout</h2>
<p>There is a standard way of reducing overfitting in neural networks called dropout. The idea of dropout is that you randomly kill some inputs to a layer during training. So the model cannot focus on using specific weights during training and therefore is forced to train all weights.</p>

<img data-src="../images/dropout.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="dropout-1" class="slide level2">
<h2>Dropout</h2>
<p><code>nn.TransformerEncoderLayer</code> already adds dropout by default with probabily to kill an input with probability <span class="math inline">\(0.1\)</span>. You can control this using the <code>dropout</code> parameter.</p>
<p>You can add dropout to your <code>Pytorch</code> model using <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html#dropout">nn.Dropout</a>.</p>
</section>
<section id="data-augmentation" class="slide level2">
<h2>Data augmentation</h2>
<p>The more data you have the better. However, getting more data to train your model might be expensive. Instead you can try generating synthetic data out of the data that you already have. This is called data augmentation.</p>
<p>Of course getting completely novel data is better, but adding synthetic data can also boost the performance of your model with almost no overhead cost.</p>
</section>
<section id="data-augmentation-1" class="slide level2">
<h2>Data augmentation</h2>
<p>If you are dealing with images you can try:</p>
<ol type="1">
<li>Cropping</li>
<li>Flipping</li>
<li>Zooming</li>
<li>Rotation</li>
<li>Hue adjustment</li>
</ol>
<p>to get images that are slightly different then the original.</p>
</section>
<section id="data-augmentation-2" class="slide level2">
<h2>Data augmentation</h2>
<p>For example, if you are doing image classification then performing the above operations will not change the class the image is in (unless you go very wild), so you will have a new sample of the class.</p>
</section>
<section id="data-augmentation-3" class="slide level2">
<h2>Data augmentation</h2>
<p>In image classification there is also an interesting data augmentation technique called mixup. Suppose matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> represent your images. Then take some <span class="math inline">\(t \in (0, 1)\)</span> and create a new image <span class="math inline">\(C = tA+(1-t)B\)</span>. The class of <span class="math inline">\(C\)</span> will also be a linear combination of the classes of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, that is if the one hot encoded labels of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <span class="math inline">\(y_A\)</span> and <span class="math inline">\(y_B\)</span>, then <span class="math inline">\(y_C = ty_A+(1-t)y_B\)</span>.</p>
<p>You can also mixup three or more images.</p>
</section>
<section id="data-augmentation-4" class="slide level2">
<h2>Data augmentation</h2>
<p>You can also augment natural text, for example you can try:</p>
<ol type="1">
<li>Replacing words with synonyms</li>
<li>Removing random words from sentences</li>
<li>Adding random words to sentences</li>
<li>Machine translating to a different language and then translating back</li>
</ol>
</section>
<section id="data-augmentation-5" class="slide level2">
<h2>Data augmentation</h2>
<p>There are two ways of implementing data augmentation in your training pipeline:</p>
<ol type="1">
<li>Offline - you augment the data before training</li>
<li>Online - you perform data augmentation during training on a batch before feeding it to the model</li>
</ol>
<p>Be aware that in NLP if your data augmentation technique has the possibility of adding new tokens to the dataset then you can’t do it in an online way.</p>
</section>
<section id="data-augmentation-6" class="slide level2">
<h2>Data augmentation</h2>
<p>This is not strictly data augmentation, but in NLP nowadays you can generate new labels using LLMs.</p>
<p>For example if you are doing text classification and have a bunch of data that is not labelled then you can get a LLM to label some of it.</p>
<p>If you write a good prompt then the accuracy of those labels will probably be around the same as you would get if you paid some company to do mass labelling for you. At least this is the case from my own personal experience.</p>
</section>
<section id="extra-tools" class="slide level2">
<h2>Extra tools</h2>
<p>Here are some extra tools that are worth looking at but we will not cover in this course:</p>
<ol type="1">
<li><a href="https://github.com/langchain-ai/langchain">LangChain</a> - a framework for working with LLMs programatically.</li>
<li><a href="https://beam.apache.org/">Apache Beam</a> - a thing that helps you write parallel data processing pipelines.</li>
<li>Also getting used to Linux might be useful at some point.</li>
</ol>
</section>
<section id="practice-task" class="slide level2">
<h2>Practice task</h2>
<ol type="1">
<li>Start working on your homework project if you have not already!</li>
</ol>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="08_extra_tricks_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="08_extra_tricks_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="08_extra_tricks_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="08_extra_tricks_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="08_extra_tricks_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="08_extra_tricks_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="08_extra_tricks_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="08_extra_tricks_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="08_extra_tricks_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="08_extra_tricks_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>