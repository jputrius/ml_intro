<!DOCTYPE html>
<html lang="en"><head>
<script src="04_feedforward_neural_networks_files/libs/clipboard/clipboard.min.js"></script>
<script src="04_feedforward_neural_networks_files/libs/quarto-html/tabby.min.js"></script>
<script src="04_feedforward_neural_networks_files/libs/quarto-html/popper.min.js"></script>
<script src="04_feedforward_neural_networks_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="04_feedforward_neural_networks_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="04_feedforward_neural_networks_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="04_feedforward_neural_networks_files/libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.24">

  <title>Chapter 4: Introduction to Feedforward Neural Networks</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="04_feedforward_neural_networks_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="04_feedforward_neural_networks_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="04_feedforward_neural_networks_files/libs/revealjs/dist/theme/quarto-9df06d9b3e1683bd31835b8738a1bbfc.css">
  <link href="04_feedforward_neural_networks_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="04_feedforward_neural_networks_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="04_feedforward_neural_networks_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="04_feedforward_neural_networks_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Chapter 4: Introduction to Feedforward Neural Networks</h1>

<div class="quarto-title-authors">
</div>

</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<p>In this chapter we introduce feedforward neural networks and backpropagation.</p>
</section>
<section id="perceptrons" class="slide level2">
<h2>Perceptrons</h2>
<p>Artificial neural networks are inspired by brains.</p>
<p>Brains are made up of neurons, artificial neural networks are made up of perceptrons.</p>
</section>
<section id="perceptrons-1" class="slide level2">
<h2>Perceptrons</h2>
<p>A perceptron <span class="math inline">\(p: \mathbb{R^n} \rightarrow \mathbb{R}\)</span> is a function which takes the following form: <span class="math display">\[
  p(x; w, b) = f\left(\sum_{i=1}^n w_ix_i+b\right),
\]</span> where <span class="math inline">\(w \in \mathbb{R^n}, b \in \mathbb{R}\)</span> are parameters called weights and bias respectively and <span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> is any non-linear function called the activation function.</p>
</section>
<section id="perceptrons-2" class="slide level2">
<h2>Perceptrons</h2>
<p>Here is a visual representation of a perceptron:</p>

<img data-src="../images/perceptron.png" class="quarto-figure quarto-figure-center r-stretch"><p>For example, taking <span class="math display">\[
  f(x) = \frac{1}{1+e^{-x}}
\]</span> we get a logistic regression model.</p>
</section>
<section id="perceptrons-3" class="slide level2">
<h2>Perceptrons</h2>
<p>There are many different choices for an activation function, see <a href="https://en.wikipedia.org/wiki/Activation_function#Table_of_activation_functions">here</a>.</p>
<p>By far the most popular nowadays is called Rectified Linear Unit or ReLU for short. It is defined as <span class="math display">\[
f(x) = \begin{cases}
  x, \text{ if } x &gt; 0;\\
  0, \text{ if } x \le 0.
\end{cases}
\]</span></p>
<p>Note that it is not differentiable at 0, however in practice this won’t cause any issues.</p>
</section>
<section id="perceptron" class="slide level2">
<h2>Perceptron</h2>
<p>Here is the graph of ReLU:</p>

<img data-src="../images/relu.svg" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="feedforward-neural-networks" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>By connecting several perceptrons together we get a (artificial) <strong>Neural Network</strong> (NN).</p>
<p>The simplest way to connect perceptrons is in a way that the resulting NN would not have any loops. Such a NN is called a <strong>Feedforward Neural Network</strong>.</p>
</section>
<section id="feedforward-neural-networks-1" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>In a feedforward NN perceptrons naturally form layers. Here is an illustration of a feedforward NN with 3 layers:</p>

<img data-src="../images/fnn.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="feedforward-neural-networks-2" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>The leftmost layer is called the input layer, the rightmost - the output layer. Middle layers are called hidden layers.</p>
<p>If a NN has at least one hidden layer it is called <strong>deep</strong>.</p>
<p>Note that the input layer does not actually contain any perceptrons. The user of the NN uses the input layer to provide their inputs.</p>
<p>We are going to count layers from 0, so the input layer is layer 0.</p>
</section>
<section id="feedforward-neural-networks-3" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>We are going to require that all perceptrons in a given layer have the same activation function.</p>
<p>We will denote the activation function of the <span class="math inline">\(i\)</span>-th layer by <span class="math inline">\(f^{[i]}.\)</span></p>
</section>
<section id="feedforward-neural-networks-4" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>Suppose layer <span class="math inline">\(i-1\)</span> contains <span class="math inline">\(n\)</span> perceptrons and layer <span class="math inline">\(i\)</span> contains <span class="math inline">\(m\)</span> perceptrons. Then the perceptrons in layer <span class="math inline">\(i\)</span> are going to take <span class="math inline">\(n\)</span> dimensional vectors as input.</p>
<p>If we collect all the weights of the <span class="math inline">\(i\)</span>-th layer into the rows of a <span class="math inline">\(m\)</span> by <span class="math inline">\(n\)</span> matrix <span class="math inline">\(W\)</span> and all the biases into an <span class="math inline">\(m\)</span> dimensional column vector <span class="math inline">\(b\)</span> then we can compute the output of the <span class="math inline">\(i\)</span>-th layer compactly as follows: <span class="math display">\[
f^{[i]}(Wx+b),
\]</span> where it is understood that we apply <span class="math inline">\(f^{[i]}\)</span> componentwise.</p>
</section>
<section id="feedforward-neural-networks-5" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>We are going to denote the weight matrix and bias vector of the <span class="math inline">\(i\)</span>-th layer by <span class="math inline">\(W^{[i]}\)</span> and <span class="math inline">\(b^{[i]}\)</span> respectively.</p>
<p>We are also going to set <span class="math display">\[
  A^{[i]}(x) = W^{[i]}x+b^{[i]},
\]</span> letter <span class="math inline">\(A\)</span> stands for affine.</p>
</section>
<section id="feedforward-neural-networks-6" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>So in our notation the output of the <span class="math inline">\(i\)</span>-th layer will be <span class="math display">\[
f^{[i]}(W^{[i]}x+b^{[i]})=f^{[i]}(A^{[i]}(x))=f^{[i]} \circ A^{[i]}(x),
\]</span> where <span class="math inline">\(\circ\)</span> denotes function composition.</p>
<p>If we denote a feedforward NN with <span class="math inline">\(l\)</span> layers by <span class="math inline">\(N\)</span>, then the output of it can be computed as <span class="math display">\[
N(x) = f^{[l]} \circ A^{[l]} \circ f^{[l-1]} \circ A^{[l-1]} \circ \dots \circ f^{[1]} \circ A^{[1]}(x).
\]</span></p>
</section>
<section id="feedforward-neural-networks-7" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>Suppose we have a classification problem with <span class="math inline">\(n\)</span> classes. Then usually the output of a feedforward NN is an <span class="math inline">\(n\)</span> dimensional vector.</p>
<p>We would like the output vector to represent confidences of the classes, that is the components should be between 0 and 1 and sum to 1. This can be achieved by applying softmax to the output.</p>
</section>
<section id="feedforward-neural-networks-8" class="slide level2">
<h2>Feedforward Neural Networks</h2>
<p>Softmax is a function from <span class="math inline">\(\mathbb{R}^n\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> whose <span class="math inline">\(i\)</span>-th component of the output is defined to be <span class="math display">\[
\text{softmax}_i(x) = \frac{e^{x_i}}{\sum_{j=1}^n e^{x_j}}.
\]</span></p>
</section>
<section id="backpropagation" class="slide level2">
<h2>Backpropagation</h2>
<p>We can apply feedforward NNs to classification and regression problems the same way we did logistic regression.</p>
<p>That is, we use a training dataset to define a loss function <span class="math inline">\(L\)</span> that depends on NN’s weights. We then train the model by minimizing <span class="math inline">\(L\)</span>, using SGD for example.</p>
<p>In order to use SGD we need an efficient way to compute the partial derivatives of <span class="math inline">\(L\)</span> with respect to weights and biases. This is done using an algorithm called backpropagation.</p>
</section>
<section id="backpropagation-1" class="slide level2">
<h2>Backpropagation</h2>
<p>The hardest part of backpropagation is not getting lost in notation.</p>
<p>To this end for a function <span class="math inline">\(f:\mathbb{R}^{m \times n} \rightarrow \mathbb{R}\)</span> define <span class="math display">\[
  \frac{\partial f}{\partial W}(W) = \begin{pmatrix}
    \frac{\partial f}{\partial w_{11}} &amp; \dots &amp; \frac{\partial f}{\partial w_{1n}} \\
    \dots &amp; \dots &amp; \dots \\
    \frac{\partial f}{\partial w_{m1}} &amp; \dots &amp; \frac{\partial f}{\partial w_{mn}}
  \end{pmatrix}
\]</span></p>
</section>
<section id="backpropagation-2" class="slide level2">
<h2>Backpropagation</h2>
<p>Suppose <span class="math inline">\(y\)</span> is an <span class="math inline">\(m\)</span> dimensional row vector and <span class="math inline">\(x\)</span> is an <span class="math inline">\(n\)</span> dimensional column vector. It is easy to show that <span class="math display">\[
y \frac{\partial}{\partial W}(Wx)=\frac{\partial}{\partial W}(yWx)=y^Tx^T.
\]</span></p>
</section>
<section id="backpropagation-3" class="slide level2">
<h2>Backpropagation</h2>
<p>Other useful derivative for us will be <span class="math display">\[
\frac{\partial A(x)}{\partial x} = \frac{\partial}{\partial x}(Wx) + \frac{\partial b}{\partial x} = W + 0 = W,
\]</span> where <span class="math display">\[
\frac{\partial A(x)}{\partial x}
\]</span> is the Jacobian of <span class="math inline">\(A\)</span>.</p>
</section>
<section id="backpropagation-4" class="slide level2">
<h2>Backpropagation</h2>
<p>If <span class="math inline">\(f\)</span> is an activation function and <span class="math inline">\(x\)</span> is an dimensional vector, then <span class="math display">\[
\frac{f(x)}{\partial x} = \text{diag}(f'(x)),
\]</span> where again <span class="math display">\[
\frac{\partial f(x)}{\partial x}
\]</span> is the Jacobian of <span class="math inline">\(f\)</span> and <span class="math inline">\(\text{diag}(f'(x))\)</span> is a diagonal <span class="math inline">\(n\)</span> by <span class="math inline">\(n\)</span> matrix with <span class="math inline">\(f'(x)\)</span> on the diagonal.</p>
</section>
<section id="backpropagation-5" class="slide level2">
<h2>Backpropagation</h2>
<p>For concreteness, we will illustrate backpropagation by example. The general case is the same.</p>
<p>Let’s figure out the formulas for backpropagation to train a model with one hidden layer for a classification problem. Our model looks like this:</p>

<img data-src="../images/fnn.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="backpropagation-6" class="slide level2">
<h2>Backpropagation</h2>
<p>So we have two affine functions <span class="math inline">\(A^{[1]}\)</span> and <span class="math inline">\(A^{[2]}\)</span> and two activation functions <span class="math inline">\(f^{[1]}\)</span> and <span class="math inline">\(f^{[2]}.\)</span> The first pair is for the hidden layer, the second pair is for the output layer.</p>
<p>We can compute the output of the model using <span class="math display">\[
N(x) = f^{[2]} \circ A^{[2]} \circ f^{[1]} \circ A^{[1]}(x).
\]</span></p>
<p>To compute the confidences of the classes we can apply softmax to <span class="math inline">\(N(x),\)</span> i.e. <span class="math display">\[
\text{confidences}(x) = \text{softmax} \circ N(x).
\]</span></p>
</section>
<section id="backpropagation-7" class="slide level2">
<h2>Backpropagation</h2>
<p>We are going to use cross-entropy for loss. Also, in implementations, cross-entropy and softmax are usually combined because the derivatives are much nicer than computing the derivatives of cross-entropy and softmax separately.</p>
</section>
<section id="backpropagation-8" class="slide level2">
<h2>Backpropagation</h2>
<p>Suppose vectors <span class="math inline">\(\{y, x\} = \{y^i, x^i\}_{i=1}^{n}\)</span> represent the training data. So the vectors <span class="math inline">\(y^i\)</span> have 0 in all components except one where it has the value 1. Suppose the dimension of <span class="math inline">\(y^i\)</span> is <span class="math inline">\(m\)</span>. Then our loss function will be <span class="math display">\[
L(W; N(x)) = \frac{1}{n} \sum_{i=1}^{n} - \log \frac{\langle y^i, e^{N(x^i; W)} \rangle}{\sum_{j=1}^n e^{N(x^i; W)_j}}
\]</span></p>
</section>
<section id="backpropagation-9" class="slide level2">
<h2>Backpropagation</h2>
<p>Then the Jacobian of <span class="math inline">\(L(W; y_{pred})\)</span> with respect to <span class="math inline">\(y_{pred}\)</span> can be computed as <span class="math display">\[
  \frac{\partial L(W; y_{pred})}{\partial y_{pred}} = \frac{1}{n} \sum_{i=1}^n \text{softmax}(y_{pred}^i) - y^i,
\]</span> where the Jacobian is a vector of same dimension as <span class="math inline">\(y^i\)</span> and the sum is componentwise. We interpret this vector as a row vector (we need to do this for matrix multiplication to be defined properly in later formulas).</p>
</section>
<section id="backpropagation-10" class="slide level2">
<h2>Backpropagation</h2>
<p>In order to train our NN we need to compute <span class="math display">\[
\frac{\partial L(W)}{\partial W^{[1]}}, \ \frac{\partial L(W)}{\partial b^{[1]}}, \ \frac{\partial L(W)}{\partial W^{[2]}}, \ \frac{\partial L(W)}{\partial b^{[2]}}.
\]</span></p>
<p>We can do this using the chain rule and formula <span class="math display">\[
y \frac{\partial}{\partial W}(Wx)=y^Tx^T.
\]</span></p>
</section>
<section id="backpropagation-11" class="slide level2">
<h2>Backpropagation</h2>
<p>We compute</p>

<img data-src="../images/backprop1.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="backpropagation-12" class="slide level2">
<h2>Backpropagation</h2>
<p>Then</p>

<img data-src="../images/backprop2.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="backpropagation-13" class="slide level2">
<h2>Backpropagation</h2>
<p>Similarly</p>

<img data-src="../images/backprop3.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="backpropagation-14" class="slide level2">
<h2>Backpropagation</h2>
<p>Also</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="../images/backprop4.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
<p>and</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="../images/backprop5.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</section>
<section id="backpropagation-15" class="slide level2">
<h2>Backpropagation</h2>
<p>So the full backpropagation algorithm consists of two steps:</p>
<ol type="1">
<li><p>Forward pass: Compute the values of <span class="math display">\[\begin{equation*}
  \begin{split}
  &amp;A^{[1]}(x), \ f^{[1]} \circ A^{[1]}(x), \\
  &amp;A^{[2]} \circ f^{[1]} \circ A^{[1]}(x), \ f^{[2]} \circ A^{[2]} \circ f^{[1]} \circ A^{[1]}(x).
\end{split}
\end{equation*}\]</span></p></li>
<li><p>Backward pass: Use the values from step one and derived formulas to compute the partial derivatives in terms of weights and biases.</p></li>
</ol>
<p>Once you have the partial derivatives you can, for example, plug them into SGD to minimize the loss and train the model.</p>
</section>
<section id="practice-task" class="slide level2">
<h2>Practice task</h2>
<p>Try to implement your own feedforward NN with one hidden layer for a classification task. Use the formulas we derived to perform backpropagation and SGD to minimize the loss function.</p>
<p>Make the hidden layer twice as big as the input layer. Use ReLU for the activation function of the first layer. Let the activation function of the output layer be the identity function, i.e.&nbsp;<span class="math inline">\(f^{[2]}(x)=x.\)</span></p>
</section>
<section id="practice-task-1" class="slide level2">
<h2>Practice task</h2>
<p>Some notes:</p>
<ol type="1">
<li><p>In theoretical considerations it is convenient to consider <span class="math inline">\(x\)</span> to be a column vector. However, in practical implementations it is more convenient to consider <span class="math inline">\(x\)</span> to be a row vector.</p></li>
<li><p>Numpy arrays have matrix multiplication operator <code>@</code>.</p></li>
</ol>
</section>
<section id="practice-task-2" class="slide level2">
<h2>Practice task</h2>
<ol start="3" type="1">
<li>You can generate some mock data for testing your implementation using sklearn:</li>
</ol>
<div id="c2015bb0" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb1-2"><a href=""></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb1-3"><a href=""></a>X, y <span class="op">=</span> make_classification(n_samples<span class="op">=</span><span class="dv">10000</span>, n_features<span class="op">=</span><span class="dv">20</span>, n_informative<span class="op">=</span><span class="dv">10</span>, n_classes<span class="op">=</span><span class="dv">3</span>, n_redundant<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">34</span>)</span>
<span id="cb1-4"><a href=""></a>y <span class="op">=</span> OneHotEncoder(sparse_output<span class="op">=</span><span class="va">False</span>).fit_transform(y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb1-5"><a href=""></a><span class="bu">print</span>(<span class="ss">f"X shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, y shape: </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>X shape: (10000, 20), y shape: (10000, 3)</code></pre>
</div>
</div>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="04_feedforward_neural_networks_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="04_feedforward_neural_networks_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>